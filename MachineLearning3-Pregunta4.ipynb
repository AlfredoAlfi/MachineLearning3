{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1> INF393 - Máquinas de Aprendizaje  </h1>\n",
    "    <h2> Tarea 3 </h2>\n",
    "    <h3> Universidad Técnica Federico Santa Maria </h3>\n",
    "    \n",
    "</center>\n",
    "\n",
    "_Diciembre 2017_\n",
    "<p>Profesor: R. Ñanculef</p>\n",
    " <p>Ayudante: Francisco Mena</p>\n",
    " <p>Integrantes: \n",
    " <br>Alfredo Silva,\n",
    " 201373511-8</br>\n",
    " <br>Fernando Llorens, 201373528-2</br>\n",
    " \n",
    "\n",
    " \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4. Reconocimiento de Imágenes Sign Gestures</h1>\n",
    "<p>\n",
    "MNIST es un dataset muy popular de dígitos escrito a mano que a servido para probar distintos algoritmos\n",
    "de Machine Learning relacionados con Computer Vision. Buscando nuevos desafíos, investigadores generaron\n",
    "un dataset que podría usarse eventualmente en aplicaciones reales, Sign Gestures, consta de imagenes del\n",
    "lenguaje de señas, estas tienen una resolución de 28x28 pixeles representados en una escala de grises 0-255.\n",
    "La versión utilizada se atribuye a y viene separada en 27455 ejemplos de entrenamiento y 7172 casos de\n",
    "pruebas. Las clases son mutualmente excluyentes y corresponden a las letras del alfabeto (imagen en PDF original).\n",
    "</p>\n",
    "<p>\n",
    "(a) Construya una función que cargue todos los datos de entrenamiento y pruebas del problema generando\n",
    "como salida: (i) dos matrices $X_{tr}$, $Y_{tr}$, correspondientes a las imágenes y etiquetas de entrenamiento,\n",
    "(ii) dos matrices $X_t$, $Y_t$, correspondientes a las imágenes y etiquetas de pruebas, y finalmente (iii) dos\n",
    "matrices $X_v$, $Y_v$, correspondientes a imágenes y etiquetas que se usarán como conjunto de validación, es\n",
    "decir para tomar decisiones de diseño acerca del modelo. Este último conjunto debe ser extraído desde\n",
    "el conjunto de entrenamiento original y no debe superar las 7000 imágenes.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN+VALIDACION-----------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27455 entries, 0 to 27454\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 164.4 MB\n",
      "TEST-----------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7172 entries, 0 to 7171\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 43.0 MB\n"
     ]
    }
   ],
   "source": [
    "#Si validacion no puede superar 7000 imagenes entonces no puede ser mas del 25% del entrenamiento,\n",
    "#para asegurarnos usaremos el 20\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "def load_data():\n",
    "    train = pd.read_csv('sign_mnist_train.csv')\n",
    "    test = pd.read_csv('sign_mnist_test.csv')\n",
    "    print(\"TRAIN+VALIDACION-----------------------------\")\n",
    "    train.shape\n",
    "    train.info()\n",
    "    train.describe()\n",
    "    print(\"TEST-----------------------------------------\")\n",
    "    test.shape\n",
    "    test.info()\n",
    "    test.describe()\n",
    "    y_tr = train['label']\n",
    "    x_tr = train.iloc[:,1:]\n",
    "    x_train, x_v, y_train, y_v = train_test_split(x_tr, y_tr, test_size=0.20, random_state=42)\n",
    "    y_t = test['label']\n",
    "    x_t = test.iloc[:,1:]\n",
    "    return(x_train,x_v,x_t,y_train,y_v,y_t)\n",
    "def contar(y):\n",
    "    counter=collections.Counter(y)\n",
    "    for i in range(len(counter.values())):\n",
    "        print(\"{} = {}\".format(counter.keys()[i],\n",
    "                                 counter.values()[i]))\n",
    "x_tr, x_v, x_t, y_tr, y_v , y_t = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22706</th>\n",
       "      <td>97</td>\n",
       "      <td>65</td>\n",
       "      <td>128</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>189</td>\n",
       "      <td>180</td>\n",
       "      <td>134</td>\n",
       "      <td>97</td>\n",
       "      <td>76</td>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>215</td>\n",
       "      <td>216</td>\n",
       "      <td>217</td>\n",
       "      <td>223</td>\n",
       "      <td>206</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>191</td>\n",
       "      <td>106</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>134</td>\n",
       "      <td>124</td>\n",
       "      <td>167</td>\n",
       "      <td>124</td>\n",
       "      <td>23</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>144</td>\n",
       "      <td>145</td>\n",
       "      <td>146</td>\n",
       "      <td>147</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>107</td>\n",
       "      <td>183</td>\n",
       "      <td>187</td>\n",
       "      <td>171</td>\n",
       "      <td>160</td>\n",
       "      <td>131</td>\n",
       "      <td>134</td>\n",
       "      <td>101</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21099</th>\n",
       "      <td>64</td>\n",
       "      <td>73</td>\n",
       "      <td>83</td>\n",
       "      <td>96</td>\n",
       "      <td>101</td>\n",
       "      <td>108</td>\n",
       "      <td>111</td>\n",
       "      <td>115</td>\n",
       "      <td>118</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>163</td>\n",
       "      <td>167</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17752</th>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>57</td>\n",
       "      <td>75</td>\n",
       "      <td>101</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>63</td>\n",
       "      <td>69</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>71</td>\n",
       "      <td>52</td>\n",
       "      <td>95</td>\n",
       "      <td>183</td>\n",
       "      <td>176</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>184</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "22706      97      65     128      44      17      67      64      66      69   \n",
       "1231      215     216     217     223     206     176     176     191     106   \n",
       "531       144     145     146     147     150     150     151     151     151   \n",
       "21099      64      73      83      96     101     108     111     115     118   \n",
       "17752      83      88      57      75     101      37      17      63      69   \n",
       "\n",
       "       pixel10    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "22706       72    ...          189       180       134        97        76   \n",
       "1231       122    ...          133       133       132       132       134   \n",
       "531        150    ...           78       107       183       187       171   \n",
       "21099      122    ...          163       167       169       169       170   \n",
       "17752       74    ...           87        71        52        95       183   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "22706        86        94        90        91        91  \n",
       "1231        124       167       124        23       140  \n",
       "531         160       131       134       101        72  \n",
       "21099       173       173       175       175       176  \n",
       "17752       176       180       182       184       186  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21964.000000\n",
       "mean        12.324121\n",
       "std          7.298931\n",
       "min          0.000000\n",
       "25%          6.000000\n",
       "50%         13.000000\n",
       "75%         19.000000\n",
       "max         24.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape\n",
    "#y_tr.info()\n",
    "y_tr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22706    10\n",
       "1231     15\n",
       "531       0\n",
       "21099    10\n",
       "17752    22\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(b) Construya una función que escale apropiadamente las imágenes antes de trabajar. Experimente sólo\n",
    "escalando los datos de acuerdo a la intensidad máxima de pixel (i.e., dividiendo por 255) y luego\n",
    "centrando y escalándolos como en actividades anteriores.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1761998  -2.09806037 -0.60012897 -2.85449181 -3.76039244 -2.53284031\n",
      "  -2.7583446  -2.86682037 -2.90983062 -2.99411405]\n",
      " [ 1.67937834  1.68848848  1.68209134  1.8015662   1.33950431  0.48377907\n",
      "   0.44027188  0.8488636  -1.77696957 -1.39475919]\n",
      " [-0.03880851 -0.09194177 -0.13855632 -0.17530759 -0.17157621 -0.23578152\n",
      "  -0.27370501 -0.34015527 -0.39916559 -0.49912047]\n",
      " [-1.97479369 -1.89744851 -1.75406059 -1.50189395 -1.49377166 -1.39814862\n",
      "  -1.41606804 -1.41027225 -1.40955517 -1.39475919]\n",
      " [-1.51499721 -1.52130128 -2.42077663 -2.0481354  -1.49377166 -3.36310253\n",
      "  -4.10062115 -2.95599679 -2.90983062 -2.93013986]\n",
      " [ 0.73558556  0.68542918  0.65637435  0.60503733  0.55698047  0.45610366\n",
      "   0.4117128   0.40298152  0.39689894  0.33254406]\n",
      " [ 0.20318964  0.28420546  0.32301633  0.31891086  0.34111182  0.34540203\n",
      "   0.38315373  0.40298152  0.39689894  0.42850535]\n",
      " [ 0.56618686  0.56004677  0.52815973  0.50099134  0.44904614  0.40075285\n",
      "   0.38315373  0.34353058  0.33566321  0.30055696]\n",
      " [-0.32920629 -0.3427066  -0.34369972 -0.35738807 -0.36046128 -0.40183396\n",
      "  -0.38794131 -0.36988074 -0.39916559 -0.43514627]\n",
      " [ 1.05018316  1.06157642  1.04101822  0.99520979  0.96173418  0.92658558\n",
      "   0.89721709  0.90831455  0.8867848   0.94029891]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\"\"\"\n",
    "std = StandardScaler(with_mean=True, with_std=True)\n",
    "std.fit(X_train)\n",
    "X_train = std.transform(X_train)\n",
    "X_test = std.transform(X_test)\n",
    "\"\"\"\n",
    "def escalador(x_tr, x_v, x_t,n=255.0):\n",
    "    #Se regula la intensidad de todos por igual\n",
    "    x_tr = np.divide(x_tr, float(n))\n",
    "    x_v = np.divide(x_v, float(n))\n",
    "    x_t = np.divide(x_t, float(n))\n",
    "    #Se centran y escalan todos los datos usando como referencia el de entrenamiento\n",
    "    #de la misma manera que en el entregable anterior\n",
    "    std = StandardScaler(with_mean=True, with_std=True)\n",
    "    std.fit(x_tr)\n",
    "    X_train = std.transform(x_tr)\n",
    "    X_val = std.transform(x_v)\n",
    "    X_test = std.transform(x_t)\n",
    "    \n",
    "    return(X_train, X_val, X_test)\n",
    "Sx_tr,Sx_v,Sx_t = escalador(x_tr,x_v,x_t)#con n 255 por defecto\n",
    "print(Sx_tr[:10,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(c) Diseñe, entrene y evalúe una red neuronal para el problema partir de la representación original de las\n",
    "imágenes. Experimente con distintas arquitecturas, pre-procesamientos y métodos de entrenamiento,\n",
    "midiendo el error de clasificación sobre el conjunto de validación. En base a esta última medida de\n",
    "desempeño, decida qué modelo, de entre todos los evaluados, medirá finalmente en el conjunto de test.\n",
    "Reporte y discuta los resultados obtenidos. Se espera que logre obtener un error de pruebas menor o\n",
    "igual a 0.2.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21964 samples, validate on 5491 samples\n",
      "Epoch 1/100\n",
      "21964/21964 [==============================] - 1s 64us/step - loss: 15.3576 - acc: 0.0409 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 2/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 3/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 4/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 5/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 6/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 7/100\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 8/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 9/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 10/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 11/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 12/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 13/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 14/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 15/100\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 16/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 17/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 18/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 19/100\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 20/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 21/100\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 22/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 23/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 24/100\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 25/100\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 26/100\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 27/100\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 28/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 29/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 30/100\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 31/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 32/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 33/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 34/100\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 35/100\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 36/100\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 37/100\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 38/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 39/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 40/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 41/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 42/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 43/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 44/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 45/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 46/100\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 47/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 48/100\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 49/100\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 50/100\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 51/100\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 52/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 53/100\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 54/100\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 55/100\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 56/100\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 57/100\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 58/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 60/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 61/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 62/100\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 63/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 64/100\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 65/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 66/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 67/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 68/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 69/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 70/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 71/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 72/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 73/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 74/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 75/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 76/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 77/100\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 78/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 79/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 80/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 81/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 82/100\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 83/100\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 84/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 85/100\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 86/100\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 87/100\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 88/100\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 89/100\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 90/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 91/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 92/100\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 93/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 94/100\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 95/100\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 96/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 97/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 98/100\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 99/100\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n",
      "Epoch 100/100\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 15.4496 - acc: 0.0415 - val_loss: 15.5105 - val_acc: 0.0377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2af83a94a20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#Con la data sin pre-procesar\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=x_tr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dense(30, init='uniform', activation='relu'))\n",
    "model.add(Dense(25, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_tr.values, to_categorical(y_tr), nb_epoch=100, batch_size=128, verbose=1,\n",
    "                        validation_data=(x_v.values,to_categorical(y_v)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21964 samples, validate on 5491 samples\n",
      "Epoch 1/50\n",
      "21964/21964 [==============================] - 1s 68us/step - loss: 15.5046 - acc: 0.0373 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 2/50\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 3/50\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 4/50\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 5/50\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 6/50\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 7/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 8/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 9/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 10/50\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 11/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 12/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 13/50\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 14/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 15/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 16/50\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 17/50\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 18/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 19/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 20/50\n",
      "21964/21964 [==============================] - 2s 68us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 21/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 22/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 23/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 24/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 25/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 26/50\n",
      "21964/21964 [==============================] - 1s 45us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 27/50\n",
      "21964/21964 [==============================] - 1s 45us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 28/50\n",
      "21964/21964 [==============================] - 1s 45us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 29/50\n",
      "21964/21964 [==============================] - 1s 47us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 30/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 31/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 32/50\n",
      "21964/21964 [==============================] - 1s 46us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 33/50\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 34/50\n",
      "21964/21964 [==============================] - 1s 45us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 35/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 36/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 37/50\n",
      "21964/21964 [==============================] - 1s 46us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 38/50\n",
      "21964/21964 [==============================] - 1s 46us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 39/50\n",
      "21964/21964 [==============================] - 1s 45us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 40/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 41/50\n",
      "21964/21964 [==============================] - 1s 47us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 42/50\n",
      "21964/21964 [==============================] - 1s 45us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 43/50\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 44/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 45/50\n",
      "21964/21964 [==============================] - 1s 46us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 46/50\n",
      "21964/21964 [==============================] - 1s 47us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 47/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 48/50\n",
      "21964/21964 [==============================] - 1s 46us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 49/50\n",
      "21964/21964 [==============================] - 1s 45us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n",
      "Epoch 50/50\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 15.5149 - acc: 0.0374 - val_loss: 15.5663 - val_acc: 0.0342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2af83c44748>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#Con la data sin pre-procesar con una capa menos y  epoch a la mitad\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(30, input_dim=x_tr.shape[1], init='uniform', activation='relu'))\n",
    "model1.add(Dense(25, init='uniform', activation='softmax'))\n",
    "model1.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model1.fit(x_tr.values, to_categorical(y_tr), nb_epoch=50, batch_size=128, verbose=1,\n",
    "                        validation_data=(x_v.values,to_categorical(y_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=\"elu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21964 samples, validate on 5491 samples\n",
      "Epoch 1/50\n",
      "21964/21964 [==============================] - 2s 70us/step - loss: 3.1546 - acc: 0.0695 - val_loss: 3.1914 - val_acc: 0.0475\n",
      "Epoch 2/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1622 - acc: 0.0526 - val_loss: 3.1729 - val_acc: 0.0514\n",
      "Epoch 3/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 3.0047 - acc: 0.0953 - val_loss: 2.7607 - val_acc: 0.1218\n",
      "Epoch 4/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 2.8467 - acc: 0.1217 - val_loss: 2.6315 - val_acc: 0.1537\n",
      "Epoch 5/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 2.7190 - acc: 0.1436 - val_loss: 2.9165 - val_acc: 0.1076\n",
      "Epoch 6/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 2.6474 - acc: 0.1572 - val_loss: 2.6558 - val_acc: 0.1382\n",
      "Epoch 7/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 2.6351 - acc: 0.1599 - val_loss: 2.6570 - val_acc: 0.1353\n",
      "Epoch 8/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 2.7142 - acc: 0.1502 - val_loss: 3.1284 - val_acc: 0.0845\n",
      "Epoch 9/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 2.7302 - acc: 0.1450 - val_loss: 2.7364 - val_acc: 0.1380\n",
      "Epoch 10/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 2.6746 - acc: 0.1496 - val_loss: 2.6845 - val_acc: 0.1346\n",
      "Epoch 11/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 2.6708 - acc: 0.1517 - val_loss: 3.0056 - val_acc: 0.0925\n",
      "Epoch 12/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.0345 - acc: 0.0824 - val_loss: 3.1260 - val_acc: 0.0504\n",
      "Epoch 13/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 3.0030 - acc: 0.0843 - val_loss: 3.3367 - val_acc: 0.0421\n",
      "Epoch 14/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1475 - acc: 0.0606 - val_loss: 2.9458 - val_acc: 0.1096\n",
      "Epoch 15/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 2.8872 - acc: 0.1257 - val_loss: 3.1469 - val_acc: 0.0799\n",
      "Epoch 16/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1494 - acc: 0.0575 - val_loss: 3.1772 - val_acc: 0.0494\n",
      "Epoch 17/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1796 - acc: 0.0427 - val_loss: 3.1783 - val_acc: 0.0475\n",
      "Epoch 18/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 3.1797 - acc: 0.0402 - val_loss: 3.1789 - val_acc: 0.0419\n",
      "Epoch 19/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 3.1794 - acc: 0.0432 - val_loss: 3.1789 - val_acc: 0.0488\n",
      "Epoch 20/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 3.1794 - acc: 0.0448 - val_loss: 3.1782 - val_acc: 0.0530\n",
      "Epoch 21/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 3.1792 - acc: 0.0421 - val_loss: 3.1777 - val_acc: 0.0488\n",
      "Epoch 22/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 3.1795 - acc: 0.0428 - val_loss: 3.1778 - val_acc: 0.0402\n",
      "Epoch 23/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 3.1792 - acc: 0.0459 - val_loss: 3.1780 - val_acc: 0.0530\n",
      "Epoch 24/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1795 - acc: 0.0453 - val_loss: 3.1775 - val_acc: 0.0488\n",
      "Epoch 25/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 3.1791 - acc: 0.0429 - val_loss: 3.1788 - val_acc: 0.0441\n",
      "Epoch 26/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1795 - acc: 0.0445 - val_loss: 3.1810 - val_acc: 0.0419\n",
      "Epoch 27/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 3.1793 - acc: 0.0429 - val_loss: 3.1783 - val_acc: 0.0441\n",
      "Epoch 28/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1797 - acc: 0.0436 - val_loss: 3.1781 - val_acc: 0.0419\n",
      "Epoch 29/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1790 - acc: 0.0427 - val_loss: 3.1774 - val_acc: 0.0494\n",
      "Epoch 30/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 3.1794 - acc: 0.0433 - val_loss: 3.1774 - val_acc: 0.0466\n",
      "Epoch 31/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 3.1792 - acc: 0.0443 - val_loss: 3.1784 - val_acc: 0.0441\n",
      "Epoch 32/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1795 - acc: 0.0421 - val_loss: 3.1781 - val_acc: 0.0475\n",
      "Epoch 33/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1792 - acc: 0.0454 - val_loss: 3.1748 - val_acc: 0.0475\n",
      "Epoch 34/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 3.1794 - acc: 0.0447 - val_loss: 3.1778 - val_acc: 0.0463\n",
      "Epoch 35/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 3.1790 - acc: 0.0451 - val_loss: 3.1787 - val_acc: 0.0413\n",
      "Epoch 36/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 3.1792 - acc: 0.0440 - val_loss: 3.1792 - val_acc: 0.0475\n",
      "Epoch 37/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1794 - acc: 0.0433 - val_loss: 3.1776 - val_acc: 0.0494\n",
      "Epoch 38/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 3.1787 - acc: 0.0445 - val_loss: 3.1821 - val_acc: 0.0399\n",
      "Epoch 39/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 3.1790 - acc: 0.0422 - val_loss: 3.1767 - val_acc: 0.0530\n",
      "Epoch 40/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 3.1790 - acc: 0.0440 - val_loss: 3.1776 - val_acc: 0.0441\n",
      "Epoch 41/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 3.1789 - acc: 0.0443 - val_loss: 3.1760 - val_acc: 0.0475\n",
      "Epoch 42/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 3.1793 - acc: 0.0438 - val_loss: 3.1766 - val_acc: 0.0488\n",
      "Epoch 43/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1791 - acc: 0.0436 - val_loss: 3.1785 - val_acc: 0.0419\n",
      "Epoch 44/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1789 - acc: 0.0441 - val_loss: 3.1794 - val_acc: 0.0475\n",
      "Epoch 45/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.1789 - acc: 0.0458 - val_loss: 3.1783 - val_acc: 0.0530\n",
      "Epoch 46/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 3.1784 - acc: 0.0444 - val_loss: 3.1770 - val_acc: 0.0494\n",
      "Epoch 47/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 3.1792 - acc: 0.0456 - val_loss: 3.1793 - val_acc: 0.0475\n",
      "Epoch 48/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 3.1788 - acc: 0.0458 - val_loss: 3.1803 - val_acc: 0.0401\n",
      "Epoch 49/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 3.1792 - acc: 0.0432 - val_loss: 3.1784 - val_acc: 0.0399\n",
      "Epoch 50/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 3.1792 - acc: 0.0407 - val_loss: 3.1771 - val_acc: 0.0530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2af8367d9b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#Con la data sin pre-procesar una capa extra con tanh- ahora se usa elu por relu\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(30, input_dim=x_tr.shape[1], init='uniform', activation='relu'))\n",
    "model2.add(Dense(30, init='uniform', activation='elu'))\n",
    "model2.add(Dense(30, init='uniform', activation='tanh'))\n",
    "model2.add(Dense(25, init='uniform', activation='softmax'))\n",
    "model2.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(x_tr.values, to_categorical(y_tr), nb_epoch=50, batch_size=128, verbose=1,\n",
    "                        validation_data=(x_v.values,to_categorical(y_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21964 samples, validate on 5491 samples\n",
      "Epoch 1/50\n",
      "21964/21964 [==============================] - 2s 78us/step - loss: 3.2123 - acc: 0.0502 - val_loss: 3.2064 - val_acc: 0.0479\n",
      "Epoch 2/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 3.2027 - acc: 0.0471 - val_loss: 3.1989 - val_acc: 0.0486\n",
      "Epoch 3/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 3.1962 - acc: 0.0492 - val_loss: 3.1930 - val_acc: 0.0586\n",
      "Epoch 4/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 3.1880 - acc: 0.0601 - val_loss: 3.1777 - val_acc: 0.0688\n",
      "Epoch 5/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 3.1452 - acc: 0.0621 - val_loss: 3.1127 - val_acc: 0.0639\n",
      "Epoch 6/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 3.0648 - acc: 0.0891 - val_loss: 3.0004 - val_acc: 0.0894\n",
      "Epoch 7/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 2.8548 - acc: 0.1054 - val_loss: 2.7215 - val_acc: 0.1074\n",
      "Epoch 8/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 2.6018 - acc: 0.1442 - val_loss: 2.5028 - val_acc: 0.1599\n",
      "Epoch 9/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 2.3737 - acc: 0.2101 - val_loss: 2.2489 - val_acc: 0.2588\n",
      "Epoch 10/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 2.0888 - acc: 0.3152 - val_loss: 1.9211 - val_acc: 0.3642\n",
      "Epoch 11/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 1.7557 - acc: 0.4291 - val_loss: 1.5734 - val_acc: 0.4766\n",
      "Epoch 12/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 1.4660 - acc: 0.5342 - val_loss: 1.6818 - val_acc: 0.4451\n",
      "Epoch 13/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 1.2742 - acc: 0.6096 - val_loss: 1.1306 - val_acc: 0.6664\n",
      "Epoch 14/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 1.0652 - acc: 0.6881 - val_loss: 1.2910 - val_acc: 0.5910\n",
      "Epoch 15/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.8957 - acc: 0.7434 - val_loss: 0.8633 - val_acc: 0.7427\n",
      "Epoch 16/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.7577 - acc: 0.7893 - val_loss: 0.9311 - val_acc: 0.6948\n",
      "Epoch 17/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.6191 - acc: 0.8321 - val_loss: 0.5203 - val_acc: 0.8678\n",
      "Epoch 18/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.5121 - acc: 0.8639 - val_loss: 0.4423 - val_acc: 0.8931\n",
      "Epoch 19/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.4522 - acc: 0.8805 - val_loss: 0.3488 - val_acc: 0.9188\n",
      "Epoch 20/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.3496 - acc: 0.9174 - val_loss: 0.2883 - val_acc: 0.9408\n",
      "Epoch 21/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.3333 - acc: 0.9231 - val_loss: 0.2885 - val_acc: 0.9346\n",
      "Epoch 22/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.2711 - acc: 0.9420 - val_loss: 1.5022 - val_acc: 0.6245\n",
      "Epoch 23/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.2105 - acc: 0.9607 - val_loss: 0.7072 - val_acc: 0.7993\n",
      "Epoch 24/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 0.2308 - acc: 0.9502 - val_loss: 0.1658 - val_acc: 0.9718\n",
      "Epoch 25/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.2354 - acc: 0.9469 - val_loss: 0.1570 - val_acc: 0.9725\n",
      "Epoch 26/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 0.1967 - acc: 0.9581 - val_loss: 0.1327 - val_acc: 0.9771\n",
      "Epoch 27/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.1285 - acc: 0.9763 - val_loss: 0.1189 - val_acc: 0.9771\n",
      "Epoch 28/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.1113 - acc: 0.9786 - val_loss: 0.1084 - val_acc: 0.9780\n",
      "Epoch 29/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.1107 - acc: 0.9774 - val_loss: 0.0999 - val_acc: 0.9794\n",
      "Epoch 30/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0907 - acc: 0.9830 - val_loss: 0.0948 - val_acc: 0.9807\n",
      "Epoch 31/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.1227 - acc: 0.9729 - val_loss: 0.0849 - val_acc: 0.9823\n",
      "Epoch 32/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0741 - acc: 0.9848 - val_loss: 0.5825 - val_acc: 0.8355\n",
      "Epoch 33/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.1055 - acc: 0.9756 - val_loss: 0.0727 - val_acc: 0.9843\n",
      "Epoch 34/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0634 - acc: 0.9893 - val_loss: 0.0670 - val_acc: 0.9885\n",
      "Epoch 35/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0587 - acc: 0.9919 - val_loss: 0.0646 - val_acc: 0.9894\n",
      "Epoch 36/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0547 - acc: 0.9933 - val_loss: 0.0588 - val_acc: 0.9913\n",
      "Epoch 37/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0510 - acc: 0.9933 - val_loss: 0.0549 - val_acc: 0.9914\n",
      "Epoch 38/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0538 - acc: 0.9916 - val_loss: 0.0531 - val_acc: 0.9914\n",
      "Epoch 39/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.1434 - acc: 0.9670 - val_loss: 0.1551 - val_acc: 0.9572\n",
      "Epoch 40/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0497 - acc: 0.9927 - val_loss: 0.0487 - val_acc: 0.9918\n",
      "Epoch 41/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0421 - acc: 0.9933 - val_loss: 0.0457 - val_acc: 0.9927\n",
      "Epoch 42/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0395 - acc: 0.9947 - val_loss: 0.0436 - val_acc: 0.9936\n",
      "Epoch 43/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0375 - acc: 0.9955 - val_loss: 0.0411 - val_acc: 0.9954\n",
      "Epoch 44/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0354 - acc: 0.9965 - val_loss: 0.0395 - val_acc: 0.9956\n",
      "Epoch 45/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0338 - acc: 0.9971 - val_loss: 0.0377 - val_acc: 0.9960\n",
      "Epoch 46/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0324 - acc: 0.9972 - val_loss: 0.0379 - val_acc: 0.9953\n",
      "Epoch 47/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.0310 - acc: 0.9976 - val_loss: 0.0349 - val_acc: 0.9956\n",
      "Epoch 48/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0302 - acc: 0.9975 - val_loss: 0.0361 - val_acc: 0.9958\n",
      "Epoch 49/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0288 - acc: 0.9978 - val_loss: 0.0327 - val_acc: 0.9965\n",
      "Epoch 50/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0276 - acc: 0.9979 - val_loss: 0.0312 - val_acc: 0.9965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2af84817d30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#Con la data pre-procesada una capa extra con tanh-\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(30, input_dim=Sx_tr.shape[1], init='uniform', activation='relu'))\n",
    "model3.add(Dense(30, init='uniform', activation='relu'))\n",
    "model3.add(Dense(30, init='uniform', activation='tanh'))\n",
    "model3.add(Dense(25, init='uniform', activation='softmax'))\n",
    "model3.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(Sx_tr, to_categorical(y_tr), nb_epoch=50, batch_size=128, verbose=1,\n",
    "                    validation_data=(Sx_v,to_categorical(y_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=\"elu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21964 samples, validate on 5491 samples\n",
      "Epoch 1/50\n",
      "21964/21964 [==============================] - 2s 74us/step - loss: 3.1812 - acc: 0.1058 - val_loss: 3.0777 - val_acc: 0.1109\n",
      "Epoch 2/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 2.6966 - acc: 0.1799 - val_loss: 2.2330 - val_acc: 0.2879\n",
      "Epoch 3/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 1.8607 - acc: 0.3869 - val_loss: 1.5684 - val_acc: 0.4821\n",
      "Epoch 4/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.3030 - acc: 0.5651 - val_loss: 1.1099 - val_acc: 0.6217\n",
      "Epoch 5/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.9110 - acc: 0.6908 - val_loss: 0.7767 - val_acc: 0.7385\n",
      "Epoch 6/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.6429 - acc: 0.7971 - val_loss: 0.5532 - val_acc: 0.8312\n",
      "Epoch 7/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.4528 - acc: 0.8669 - val_loss: 0.4136 - val_acc: 0.8694\n",
      "Epoch 8/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.3145 - acc: 0.9199 - val_loss: 0.2848 - val_acc: 0.9195\n",
      "Epoch 9/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.2115 - acc: 0.9564 - val_loss: 0.1874 - val_acc: 0.9656\n",
      "Epoch 10/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.1414 - acc: 0.9806 - val_loss: 0.1242 - val_acc: 0.9842\n",
      "Epoch 11/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0958 - acc: 0.9921 - val_loss: 0.0837 - val_acc: 0.9945\n",
      "Epoch 12/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0659 - acc: 0.9980 - val_loss: 0.0608 - val_acc: 0.9985\n",
      "Epoch 13/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0475 - acc: 0.9994 - val_loss: 0.0445 - val_acc: 0.9985\n",
      "Epoch 14/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0361 - acc: 0.9996 - val_loss: 0.0344 - val_acc: 0.9991\n",
      "Epoch 15/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0284 - acc: 0.9998 - val_loss: 0.0278 - val_acc: 0.9993\n",
      "Epoch 16/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0232 - acc: 0.9997 - val_loss: 0.0232 - val_acc: 0.9996\n",
      "Epoch 17/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0192 - acc: 0.9999 - val_loss: 0.0200 - val_acc: 0.9995\n",
      "Epoch 18/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0163 - acc: 0.9998 - val_loss: 0.0171 - val_acc: 0.9995\n",
      "Epoch 19/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0141 - acc: 0.9999 - val_loss: 0.0150 - val_acc: 0.9995\n",
      "Epoch 20/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0124 - acc: 0.9999 - val_loss: 0.0132 - val_acc: 0.9998\n",
      "Epoch 21/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9998\n",
      "Epoch 22/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9998\n",
      "Epoch 23/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9996\n",
      "Epoch 24/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9998\n",
      "Epoch 25/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 0.9998\n",
      "Epoch 26/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9996\n",
      "Epoch 27/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9996\n",
      "Epoch 28/50\n",
      "21964/21964 [==============================] - 1s 61us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9998\n",
      "Epoch 29/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9996\n",
      "Epoch 30/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9998\n",
      "Epoch 31/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9998\n",
      "Epoch 32/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9998\n",
      "Epoch 33/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 0.9998\n",
      "Epoch 34/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9998\n",
      "Epoch 35/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9998\n",
      "Epoch 36/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9998\n",
      "Epoch 37/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9998\n",
      "Epoch 38/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9998\n",
      "Epoch 39/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9998\n",
      "Epoch 40/50\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9996\n",
      "Epoch 41/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9998\n",
      "Epoch 42/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9998\n",
      "Epoch 43/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9998\n",
      "Epoch 44/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9998\n",
      "Epoch 45/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9998\n",
      "Epoch 46/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9998\n",
      "Epoch 47/50\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9998\n",
      "Epoch 48/50\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9998\n",
      "Epoch 49/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9998\n",
      "Epoch 50/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2af8329a320>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#Con la data pre-procesada una capa menos a la anterior y una capa ahora usa elu en vez de relu\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(30, input_dim=Sx_tr.shape[1], init='uniform', activation='relu'))\n",
    "model4.add(Dense(30, init='uniform', activation='elu'))\n",
    "model4.add(Dense(25, init='uniform', activation='softmax'))\n",
    "model4.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model4.fit(Sx_tr, to_categorical(y_tr), nb_epoch=50, batch_size=128, verbose=1,\n",
    "                    validation_data=(Sx_v,to_categorical(y_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, activation=\"linear\", kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=\"elu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21964 samples, validate on 5491 samples\n",
      "Epoch 1/50\n",
      "21964/21964 [==============================] - 2s 74us/step - loss: 2.9809 - acc: 0.1403 - val_loss: 2.5406 - val_acc: 0.2001\n",
      "Epoch 2/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 2.0246 - acc: 0.3442 - val_loss: 1.6692 - val_acc: 0.4409\n",
      "Epoch 3/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.4119 - acc: 0.5270 - val_loss: 1.2359 - val_acc: 0.5830\n",
      "Epoch 4/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.0372 - acc: 0.6475 - val_loss: 0.9296 - val_acc: 0.6724\n",
      "Epoch 5/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.7752 - acc: 0.7468 - val_loss: 0.6941 - val_acc: 0.7705\n",
      "Epoch 6/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.5764 - acc: 0.8217 - val_loss: 0.5204 - val_acc: 0.8403\n",
      "Epoch 7/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.4240 - acc: 0.8776 - val_loss: 0.3819 - val_acc: 0.8913\n",
      "Epoch 8/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.3091 - acc: 0.9227 - val_loss: 0.2968 - val_acc: 0.9164\n",
      "Epoch 9/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.2196 - acc: 0.9542 - val_loss: 0.1894 - val_acc: 0.9638\n",
      "Epoch 10/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.1507 - acc: 0.9788 - val_loss: 0.1366 - val_acc: 0.9823\n",
      "Epoch 11/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.1066 - acc: 0.9893 - val_loss: 0.0927 - val_acc: 0.9931\n",
      "Epoch 12/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0745 - acc: 0.9958 - val_loss: 0.0709 - val_acc: 0.9980\n",
      "Epoch 13/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0556 - acc: 0.9978 - val_loss: 0.0545 - val_acc: 0.9976\n",
      "Epoch 14/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0426 - acc: 0.9989 - val_loss: 0.0414 - val_acc: 0.9987\n",
      "Epoch 15/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0341 - acc: 0.9991 - val_loss: 0.0331 - val_acc: 0.9991\n",
      "Epoch 16/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0279 - acc: 0.9997 - val_loss: 0.0280 - val_acc: 0.9993\n",
      "Epoch 17/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0238 - acc: 0.9996 - val_loss: 0.0240 - val_acc: 0.9993\n",
      "Epoch 18/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0201 - acc: 0.9998 - val_loss: 0.0210 - val_acc: 0.9991\n",
      "Epoch 19/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0174 - acc: 0.9998 - val_loss: 0.0185 - val_acc: 0.9993\n",
      "Epoch 20/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0152 - acc: 0.9998 - val_loss: 0.0162 - val_acc: 0.9995\n",
      "Epoch 21/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.0137 - acc: 0.9998 - val_loss: 0.0150 - val_acc: 0.9995\n",
      "Epoch 22/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0122 - acc: 0.9999 - val_loss: 0.0136 - val_acc: 0.9993\n",
      "Epoch 23/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0110 - acc: 0.9999 - val_loss: 0.0124 - val_acc: 0.9995\n",
      "Epoch 24/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0101 - acc: 0.9999 - val_loss: 0.0113 - val_acc: 0.9995\n",
      "Epoch 25/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.0092 - acc: 0.9999 - val_loss: 0.0106 - val_acc: 0.9995\n",
      "Epoch 26/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9991\n",
      "Epoch 27/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0079 - acc: 0.9999 - val_loss: 0.0091 - val_acc: 0.9995\n",
      "Epoch 28/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9995\n",
      "Epoch 29/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9995\n",
      "Epoch 30/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 0.9995\n",
      "Epoch 31/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9995\n",
      "Epoch 32/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9995\n",
      "Epoch 33/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9995\n",
      "Epoch 34/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9995\n",
      "Epoch 35/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9995\n",
      "Epoch 36/50\n",
      "21964/21964 [==============================] - 1s 60us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9995\n",
      "Epoch 37/50\n",
      "21964/21964 [==============================] - 1s 60us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9995\n",
      "Epoch 38/50\n",
      "21964/21964 [==============================] - 1s 60us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9995\n",
      "Epoch 39/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9995\n",
      "Epoch 40/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9995\n",
      "Epoch 41/50\n",
      "21964/21964 [==============================] - 1s 60us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9995\n",
      "Epoch 42/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9995\n",
      "Epoch 43/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9995\n",
      "Epoch 44/50\n",
      "21964/21964 [==============================] - 1s 60us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9995\n",
      "Epoch 45/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9995\n",
      "Epoch 46/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9995\n",
      "Epoch 47/50\n",
      "21964/21964 [==============================] - 1s 60us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9995\n",
      "Epoch 48/50\n",
      "21964/21964 [==============================] - 1s 62us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9995\n",
      "Epoch 49/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9995\n",
      "Epoch 50/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2af82e94ac8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#Con la data pre-procesada capa inicial con activacion lineal\n",
    "########Con LINEAL al final no aprende :O####################\n",
    "model5 = Sequential()\n",
    "model5.add(Dense(30, input_dim=Sx_tr.shape[1], init='uniform', activation='linear'))\n",
    "model5.add(Dense(30, init='uniform', activation='elu'))\n",
    "model5.add(Dense(25, init='uniform', activation='softmax'))\n",
    "model5.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model5.fit(Sx_tr, to_categorical(y_tr), nb_epoch=50, batch_size=128, verbose=1,\n",
    "                    validation_data=(Sx_v,to_categorical(y_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=\"elu\", kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21964 samples, validate on 5491 samples\n",
      "Epoch 1/50\n",
      "21964/21964 [==============================] - 2s 74us/step - loss: 3.1829 - acc: 0.1035 - val_loss: 3.0938 - val_acc: 0.1457\n",
      "Epoch 2/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 2.7606 - acc: 0.1698 - val_loss: 2.2827 - val_acc: 0.2657\n",
      "Epoch 3/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.8727 - acc: 0.3763 - val_loss: 1.5796 - val_acc: 0.4626\n",
      "Epoch 4/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 1.2998 - acc: 0.5705 - val_loss: 1.0871 - val_acc: 0.6323\n",
      "Epoch 5/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.8860 - acc: 0.7166 - val_loss: 0.7680 - val_acc: 0.7514\n",
      "Epoch 6/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.6157 - acc: 0.8134 - val_loss: 0.5432 - val_acc: 0.8419\n",
      "Epoch 7/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.4245 - acc: 0.8905 - val_loss: 0.3831 - val_acc: 0.9035\n",
      "Epoch 8/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.2906 - acc: 0.9337 - val_loss: 0.2626 - val_acc: 0.9383\n",
      "Epoch 9/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.1951 - acc: 0.9632 - val_loss: 0.1720 - val_acc: 0.9712\n",
      "Epoch 10/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.1278 - acc: 0.9840 - val_loss: 0.1156 - val_acc: 0.9852\n",
      "Epoch 11/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0852 - acc: 0.9940 - val_loss: 0.0781 - val_acc: 0.9947\n",
      "Epoch 12/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0592 - acc: 0.9979 - val_loss: 0.0550 - val_acc: 0.9985\n",
      "Epoch 13/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0433 - acc: 0.9993 - val_loss: 0.0416 - val_acc: 0.9993\n",
      "Epoch 14/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0330 - acc: 0.9997 - val_loss: 0.0330 - val_acc: 0.9996\n",
      "Epoch 15/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0262 - acc: 0.9998 - val_loss: 0.0266 - val_acc: 0.9996\n",
      "Epoch 16/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0214 - acc: 0.9999 - val_loss: 0.0224 - val_acc: 0.9996\n",
      "Epoch 17/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 0.9995\n",
      "Epoch 18/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 0.9995\n",
      "Epoch 19/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 0.9996\n",
      "Epoch 20/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9996\n",
      "Epoch 21/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9998\n",
      "Epoch 22/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9996\n",
      "Epoch 23/50\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9996\n",
      "Epoch 24/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9996\n",
      "Epoch 25/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9998\n",
      "Epoch 26/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9996\n",
      "Epoch 27/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9998\n",
      "Epoch 28/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9998\n",
      "Epoch 29/50\n",
      "21964/21964 [==============================] - 1s 63us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "21964/21964 [==============================] - 1s 68us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 0.9998\n",
      "Epoch 31/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9998\n",
      "Epoch 32/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9998\n",
      "Epoch 33/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9998\n",
      "Epoch 34/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9998\n",
      "Epoch 35/50\n",
      "21964/21964 [==============================] - ETA: 0s - loss: 0.0037 - acc: 1.000 - 1s 55us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9998\n",
      "Epoch 36/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9998\n",
      "Epoch 37/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9998\n",
      "Epoch 38/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "21964/21964 [==============================] - 2s 72us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9998\n",
      "Epoch 40/50\n",
      "21964/21964 [==============================] - 1s 63us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9998\n",
      "Epoch 41/50\n",
      "21964/21964 [==============================] - 1s 64us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 0.9998\n",
      "Epoch 42/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9998\n",
      "Epoch 43/50\n",
      "21964/21964 [==============================] - 2s 69us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "21964/21964 [==============================] - 2s 75us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9998\n",
      "Epoch 45/50\n",
      "21964/21964 [==============================] - 1s 64us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9998\n",
      "Epoch 46/50\n",
      "21964/21964 [==============================] - 2s 75us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9998\n",
      "Epoch 47/50\n",
      "21964/21964 [==============================] - 1s 66us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9998\n",
      "Epoch 49/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9998\n",
      "Epoch 50/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2af852a9a90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2x_tr,S2x_v,S2x_t = escalador(x_tr,x_v,x_t,n=100.0)#con n 100, no tiene mucha diferencia con hacer n 255\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#Con la data pre-procesada una capa menos a la anterior y una capa ahora usa elu en vez de relu\n",
    "model6 = Sequential()\n",
    "model6.add(Dense(30, input_dim=S2x_tr.shape[1], init='uniform', activation='relu'))\n",
    "model6.add(Dense(30, init='uniform', activation='elu'))\n",
    "model6.add(Dense(25, init='uniform', activation='softmax'))\n",
    "model6.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model6.fit(S2x_tr, to_categorical(y_tr), nb_epoch=50, batch_size=128, verbose=1,\n",
    "                    validation_data=(S2x_v,to_categorical(y_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, activation=\"elu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21964 samples, validate on 5491 samples\n",
      "Epoch 1/150\n",
      "21964/21964 [==============================] - 2s 78us/step - loss: 1.0008 - acc: 0.0342 - val_loss: 1.0007 - val_acc: 0.0412\n",
      "Epoch 2/150\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 1.0007 - acc: 0.0387 - val_loss: 1.0006 - val_acc: 0.0450\n",
      "Epoch 3/150\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 1.0006 - acc: 0.0481 - val_loss: 1.0005 - val_acc: 0.0534\n",
      "Epoch 4/150\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 1.0005 - acc: 0.0577 - val_loss: 1.0005 - val_acc: 0.0634\n",
      "Epoch 5/150\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 1.0004 - acc: 0.0690 - val_loss: 1.0004 - val_acc: 0.0745\n",
      "Epoch 6/150\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 1.0004 - acc: 0.0821 - val_loss: 1.0004 - val_acc: 0.0887\n",
      "Epoch 7/150\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 1.0004 - acc: 0.0963 - val_loss: 1.0003 - val_acc: 0.1020\n",
      "Epoch 8/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 1.0003 - acc: 0.1083 - val_loss: 1.0003 - val_acc: 0.1142\n",
      "Epoch 9/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.0003 - acc: 0.1212 - val_loss: 1.0003 - val_acc: 0.1258\n",
      "Epoch 10/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.0003 - acc: 0.1365 - val_loss: 1.0003 - val_acc: 0.1430\n",
      "Epoch 11/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.0003 - acc: 0.1509 - val_loss: 1.0002 - val_acc: 0.1543\n",
      "Epoch 12/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 1.0002 - acc: 0.1665 - val_loss: 1.0002 - val_acc: 0.1685\n",
      "Epoch 13/150\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 1.0002 - acc: 0.1779 - val_loss: 1.0002 - val_acc: 0.1823\n",
      "Epoch 14/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 1.0002 - acc: 0.1877 - val_loss: 1.0002 - val_acc: 0.1916\n",
      "Epoch 15/150\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 1.0002 - acc: 0.1993 - val_loss: 1.0002 - val_acc: 0.2027\n",
      "Epoch 16/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.0002 - acc: 0.2114 - val_loss: 1.0002 - val_acc: 0.2158\n",
      "Epoch 17/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.0002 - acc: 0.2233 - val_loss: 1.0002 - val_acc: 0.2244\n",
      "Epoch 18/150\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 1.0001 - acc: 0.2312 - val_loss: 1.0001 - val_acc: 0.2360\n",
      "Epoch 19/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 1.0001 - acc: 0.2410 - val_loss: 1.0001 - val_acc: 0.2431\n",
      "Epoch 20/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.0001 - acc: 0.2496 - val_loss: 1.0001 - val_acc: 0.2502\n",
      "Epoch 21/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 1.0001 - acc: 0.2591 - val_loss: 1.0001 - val_acc: 0.2568\n",
      "Epoch 22/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.0001 - acc: 0.2683 - val_loss: 1.0001 - val_acc: 0.2628\n",
      "Epoch 23/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.0001 - acc: 0.2764 - val_loss: 1.0001 - val_acc: 0.2741\n",
      "Epoch 24/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.0001 - acc: 0.2870 - val_loss: 1.0001 - val_acc: 0.2830\n",
      "Epoch 25/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.0001 - acc: 0.2966 - val_loss: 1.0001 - val_acc: 0.2914\n",
      "Epoch 26/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.0001 - acc: 0.3050 - val_loss: 1.0001 - val_acc: 0.3005\n",
      "Epoch 27/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.0001 - acc: 0.3158 - val_loss: 1.0001 - val_acc: 0.3080\n",
      "Epoch 28/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.0001 - acc: 0.3230 - val_loss: 1.0001 - val_acc: 0.3169\n",
      "Epoch 29/150\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 1.0001 - acc: 0.3316 - val_loss: 1.0001 - val_acc: 0.3247\n",
      "Epoch 30/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 1.0001 - acc: 0.3382 - val_loss: 1.0001 - val_acc: 0.3302\n",
      "Epoch 31/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 1.0000 - acc: 0.3463 - val_loss: 1.0000 - val_acc: 0.3398\n",
      "Epoch 32/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 1.0000 - acc: 0.3527 - val_loss: 1.0000 - val_acc: 0.3475\n",
      "Epoch 33/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.0000 - acc: 0.3591 - val_loss: 1.0000 - val_acc: 0.3526\n",
      "Epoch 34/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 1.0000 - acc: 0.3648 - val_loss: 1.0000 - val_acc: 0.3584\n",
      "Epoch 35/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.0000 - acc: 0.3709 - val_loss: 1.0000 - val_acc: 0.3684\n",
      "Epoch 36/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.0000 - acc: 0.3762 - val_loss: 1.0000 - val_acc: 0.3739\n",
      "Epoch 37/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.0000 - acc: 0.3806 - val_loss: 1.0000 - val_acc: 0.3779\n",
      "Epoch 38/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.0000 - acc: 0.3869 - val_loss: 1.0000 - val_acc: 0.3808\n",
      "Epoch 39/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 1.0000 - acc: 0.3903 - val_loss: 1.0000 - val_acc: 0.3872\n",
      "Epoch 40/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.0000 - acc: 0.3962 - val_loss: 1.0000 - val_acc: 0.3875\n",
      "Epoch 41/150\n",
      "21964/21964 [==============================] - ETA: 0s - loss: 1.0000 - acc: 0.400 - 1s 55us/step - loss: 1.0000 - acc: 0.4003 - val_loss: 1.0000 - val_acc: 0.3950\n",
      "Epoch 42/150\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 1.0000 - acc: 0.4053 - val_loss: 1.0000 - val_acc: 0.3968\n",
      "Epoch 43/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 1.0000 - acc: 0.4104 - val_loss: 1.0000 - val_acc: 0.4047\n",
      "Epoch 44/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.0000 - acc: 0.4136 - val_loss: 1.0000 - val_acc: 0.4094\n",
      "Epoch 45/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.0000 - acc: 0.4189 - val_loss: 1.0000 - val_acc: 0.4116\n",
      "Epoch 46/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.0000 - acc: 0.4217 - val_loss: 1.0000 - val_acc: 0.4169\n",
      "Epoch 47/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 1.0000 - acc: 0.4260 - val_loss: 1.0000 - val_acc: 0.4209\n",
      "Epoch 48/150\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 1.0000 - acc: 0.4309 - val_loss: 1.0000 - val_acc: 0.4203\n",
      "Epoch 49/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9999 - acc: 0.4325 - val_loss: 1.0000 - val_acc: 0.4251\n",
      "Epoch 50/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.9999 - acc: 0.4364 - val_loss: 0.9999 - val_acc: 0.4262\n",
      "Epoch 51/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.9999 - acc: 0.4389 - val_loss: 0.9999 - val_acc: 0.4354\n",
      "Epoch 52/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9999 - acc: 0.4403 - val_loss: 0.9999 - val_acc: 0.4416\n",
      "Epoch 53/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.9999 - acc: 0.4458 - val_loss: 0.9999 - val_acc: 0.4351\n",
      "Epoch 54/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9999 - acc: 0.4454 - val_loss: 0.9999 - val_acc: 0.4365\n",
      "Epoch 55/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.9999 - acc: 0.4491 - val_loss: 0.9999 - val_acc: 0.4425\n",
      "Epoch 56/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.9999 - acc: 0.4502 - val_loss: 0.9999 - val_acc: 0.4506\n",
      "Epoch 57/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.9999 - acc: 0.4558 - val_loss: 0.9999 - val_acc: 0.4460\n",
      "Epoch 58/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9999 - acc: 0.4557 - val_loss: 0.9999 - val_acc: 0.4496\n",
      "Epoch 59/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.9999 - acc: 0.4574 - val_loss: 0.9999 - val_acc: 0.4520\n",
      "Epoch 60/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.9999 - acc: 0.4606 - val_loss: 0.9999 - val_acc: 0.4522\n",
      "Epoch 61/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.9999 - acc: 0.4633 - val_loss: 0.9999 - val_acc: 0.4578\n",
      "Epoch 62/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9998 - acc: 0.4665 - val_loss: 0.9999 - val_acc: 0.4637\n",
      "Epoch 63/150\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.9998 - acc: 0.4674 - val_loss: 0.9998 - val_acc: 0.4598\n",
      "Epoch 64/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9998 - acc: 0.4674 - val_loss: 0.9998 - val_acc: 0.4671\n",
      "Epoch 65/150\n",
      "21964/21964 [==============================] - 1s 62us/step - loss: 0.9998 - acc: 0.4695 - val_loss: 0.9998 - val_acc: 0.4655\n",
      "Epoch 66/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.9998 - acc: 0.4711 - val_loss: 0.9998 - val_acc: 0.4629\n",
      "Epoch 67/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.9998 - acc: 0.4728 - val_loss: 0.9998 - val_acc: 0.4691\n",
      "Epoch 68/150\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 0.9998 - acc: 0.4726 - val_loss: 0.9998 - val_acc: 0.4686\n",
      "Epoch 69/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9997 - acc: 0.4749 - val_loss: 0.9998 - val_acc: 0.4706\n",
      "Epoch 70/150\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.9997 - acc: 0.4771 - val_loss: 0.9997 - val_acc: 0.4699\n",
      "Epoch 71/150\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.9997 - acc: 0.4771 - val_loss: 0.9997 - val_acc: 0.4711\n",
      "Epoch 72/150\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 0.9997 - acc: 0.4779 - val_loss: 0.9997 - val_acc: 0.4730\n",
      "Epoch 73/150\n",
      "21964/21964 [==============================] - 1s 47us/step - loss: 0.9996 - acc: 0.4793 - val_loss: 0.9997 - val_acc: 0.4740\n",
      "Epoch 74/150\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 0.9996 - acc: 0.4771 - val_loss: 0.9996 - val_acc: 0.4740\n",
      "Epoch 75/150\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 0.9996 - acc: 0.4773 - val_loss: 0.9996 - val_acc: 0.4757\n",
      "Epoch 76/150\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 0.9995 - acc: 0.4781 - val_loss: 0.9996 - val_acc: 0.4731\n",
      "Epoch 77/150\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 0.9995 - acc: 0.4766 - val_loss: 0.9995 - val_acc: 0.4726\n",
      "Epoch 78/150\n",
      "21964/21964 [==============================] - 1s 47us/step - loss: 0.9994 - acc: 0.4764 - val_loss: 0.9994 - val_acc: 0.4657\n",
      "Epoch 79/150\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 0.9993 - acc: 0.4741 - val_loss: 0.9994 - val_acc: 0.4608\n",
      "Epoch 80/150\n",
      "21964/21964 [==============================] - 1s 47us/step - loss: 0.9992 - acc: 0.4708 - val_loss: 0.9992 - val_acc: 0.4629\n",
      "Epoch 81/150\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 0.9991 - acc: 0.4671 - val_loss: 0.9991 - val_acc: 0.4542\n",
      "Epoch 82/150\n",
      "21964/21964 [==============================] - 1s 50us/step - loss: 0.9989 - acc: 0.4589 - val_loss: 0.9989 - val_acc: 0.4467\n",
      "Epoch 83/150\n",
      "21964/21964 [==============================] - 1s 48us/step - loss: 0.9985 - acc: 0.4494 - val_loss: 0.9984 - val_acc: 0.4342\n",
      "Epoch 84/150\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.9976 - acc: 0.4306 - val_loss: 0.9970 - val_acc: 0.4043\n",
      "Epoch 85/150\n",
      "21964/21964 [==============================] - 1s 47us/step - loss: 0.9930 - acc: 0.3886 - val_loss: 0.9888 - val_acc: 0.3416\n",
      "Epoch 86/150\n",
      "21964/21964 [==============================] - 1s 49us/step - loss: 0.9828 - acc: 0.3727 - val_loss: 0.9815 - val_acc: 0.3733\n",
      "Epoch 87/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.9769 - acc: 0.3922 - val_loss: 0.9775 - val_acc: 0.3901\n",
      "Epoch 88/150\n",
      "21964/21964 [==============================] - 1s 51us/step - loss: 0.9732 - acc: 0.4052 - val_loss: 0.9746 - val_acc: 0.3923\n",
      "Epoch 89/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.9703 - acc: 0.4084 - val_loss: 0.9721 - val_acc: 0.3997\n",
      "Epoch 90/150\n",
      "21964/21964 [==============================] - 1s 62us/step - loss: 0.9679 - acc: 0.4162 - val_loss: 0.9697 - val_acc: 0.4114\n",
      "Epoch 91/150\n",
      "21964/21964 [==============================] - 1s 61us/step - loss: 0.9658 - acc: 0.4232 - val_loss: 0.9678 - val_acc: 0.4187\n",
      "Epoch 92/150\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 0.9642 - acc: 0.4296 - val_loss: 0.9663 - val_acc: 0.4292\n",
      "Epoch 93/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9629 - acc: 0.4349 - val_loss: 0.9650 - val_acc: 0.4298\n",
      "Epoch 94/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9619 - acc: 0.4370 - val_loss: 0.9641 - val_acc: 0.4440\n",
      "Epoch 95/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.9611 - acc: 0.4438 - val_loss: 0.9633 - val_acc: 0.4442\n",
      "Epoch 96/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.9604 - acc: 0.4499 - val_loss: 0.9627 - val_acc: 0.4516\n",
      "Epoch 97/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.9600 - acc: 0.4556 - val_loss: 0.9622 - val_acc: 0.4609\n",
      "Epoch 98/150\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.9596 - acc: 0.4613 - val_loss: 0.9619 - val_acc: 0.4608\n",
      "Epoch 99/150\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.9594 - acc: 0.4643 - val_loss: 0.9616 - val_acc: 0.4649\n",
      "Epoch 100/150\n",
      "21964/21964 [==============================] - 1s 61us/step - loss: 0.9591 - acc: 0.4715 - val_loss: 0.9615 - val_acc: 0.4675\n",
      "Epoch 101/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9590 - acc: 0.4772 - val_loss: 0.9613 - val_acc: 0.4600\n",
      "Epoch 102/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9589 - acc: 0.4788 - val_loss: 0.9612 - val_acc: 0.4702\n",
      "Epoch 103/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9588 - acc: 0.4867 - val_loss: 0.9611 - val_acc: 0.4677\n",
      "Epoch 104/150\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.9587 - acc: 0.4879 - val_loss: 0.9610 - val_acc: 0.4757\n",
      "Epoch 105/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.9586 - acc: 0.4913 - val_loss: 0.9610 - val_acc: 0.4708\n",
      "Epoch 106/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9586 - acc: 0.4920 - val_loss: 0.9609 - val_acc: 0.4817\n",
      "Epoch 107/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9585 - acc: 0.4958 - val_loss: 0.9608 - val_acc: 0.4781\n",
      "Epoch 108/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9585 - acc: 0.4978 - val_loss: 0.9608 - val_acc: 0.4766\n",
      "Epoch 109/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.9584 - acc: 0.4996 - val_loss: 0.9607 - val_acc: 0.4762\n",
      "Epoch 110/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.9584 - acc: 0.4990 - val_loss: 0.9606 - val_acc: 0.4883\n",
      "Epoch 111/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9583 - acc: 0.5006 - val_loss: 0.9605 - val_acc: 0.4791\n",
      "Epoch 112/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.9581 - acc: 0.4969 - val_loss: 0.9603 - val_acc: 0.4915\n",
      "Epoch 113/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9579 - acc: 0.4991 - val_loss: 0.9601 - val_acc: 0.4832\n",
      "Epoch 114/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9578 - acc: 0.4999 - val_loss: 0.9599 - val_acc: 0.4817\n",
      "Epoch 115/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9576 - acc: 0.4976 - val_loss: 0.9598 - val_acc: 0.4833\n",
      "Epoch 116/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9575 - acc: 0.4965 - val_loss: 0.9597 - val_acc: 0.4842\n",
      "Epoch 117/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9575 - acc: 0.4979 - val_loss: 0.9596 - val_acc: 0.4852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 0.9574 - acc: 0.4973 - val_loss: 0.9595 - val_acc: 0.4826\n",
      "Epoch 119/150\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 0.9573 - acc: 0.4943 - val_loss: 0.9594 - val_acc: 0.4872\n",
      "Epoch 120/150\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.9572 - acc: 0.4946 - val_loss: 0.9593 - val_acc: 0.4830\n",
      "Epoch 121/150\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.9571 - acc: 0.4939 - val_loss: 0.9592 - val_acc: 0.4817\n",
      "Epoch 122/150\n",
      "21964/21964 [==============================] - 1s 60us/step - loss: 0.9569 - acc: 0.4935 - val_loss: 0.9590 - val_acc: 0.4764\n",
      "Epoch 123/150\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.9567 - acc: 0.4921 - val_loss: 0.9587 - val_acc: 0.4762\n",
      "Epoch 124/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.9563 - acc: 0.4871 - val_loss: 0.9583 - val_acc: 0.4679\n",
      "Epoch 125/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9554 - acc: 0.4774 - val_loss: 0.9571 - val_acc: 0.4580\n",
      "Epoch 126/150\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.9519 - acc: 0.4529 - val_loss: 0.9511 - val_acc: 0.4079\n",
      "Epoch 127/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.9424 - acc: 0.4322 - val_loss: 0.9431 - val_acc: 0.4313\n",
      "Epoch 128/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.9354 - acc: 0.4521 - val_loss: 0.9380 - val_acc: 0.4487\n",
      "Epoch 129/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9308 - acc: 0.4650 - val_loss: 0.9343 - val_acc: 0.4560\n",
      "Epoch 130/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.9275 - acc: 0.4721 - val_loss: 0.9315 - val_acc: 0.4617\n",
      "Epoch 131/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9250 - acc: 0.4733 - val_loss: 0.9294 - val_acc: 0.4566\n",
      "Epoch 132/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.9230 - acc: 0.4742 - val_loss: 0.9276 - val_acc: 0.4626\n",
      "Epoch 133/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9212 - acc: 0.4766 - val_loss: 0.9261 - val_acc: 0.4604\n",
      "Epoch 134/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.9195 - acc: 0.4768 - val_loss: 0.9246 - val_acc: 0.4644\n",
      "Epoch 135/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.9176 - acc: 0.4760 - val_loss: 0.9229 - val_acc: 0.4564\n",
      "Epoch 136/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.9149 - acc: 0.4700 - val_loss: 0.9200 - val_acc: 0.4542\n",
      "Epoch 137/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.9098 - acc: 0.4572 - val_loss: 0.9107 - val_acc: 0.4407\n",
      "Epoch 138/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.8991 - acc: 0.4581 - val_loss: 0.9008 - val_acc: 0.4511\n",
      "Epoch 139/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.8920 - acc: 0.4755 - val_loss: 0.8952 - val_acc: 0.4675\n",
      "Epoch 140/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.8880 - acc: 0.4886 - val_loss: 0.8915 - val_acc: 0.4748\n",
      "Epoch 141/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.8850 - acc: 0.4952 - val_loss: 0.8888 - val_acc: 0.4795\n",
      "Epoch 142/150\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.8828 - acc: 0.4990 - val_loss: 0.8867 - val_acc: 0.4852\n",
      "Epoch 143/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.8809 - acc: 0.4983 - val_loss: 0.8850 - val_acc: 0.4824\n",
      "Epoch 144/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.8794 - acc: 0.4991 - val_loss: 0.8835 - val_acc: 0.4892\n",
      "Epoch 145/150\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.8780 - acc: 0.4986 - val_loss: 0.8820 - val_acc: 0.4795\n",
      "Epoch 146/150\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.8765 - acc: 0.4943 - val_loss: 0.8804 - val_acc: 0.4740\n",
      "Epoch 147/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.8745 - acc: 0.4902 - val_loss: 0.8775 - val_acc: 0.4662\n",
      "Epoch 148/150\n",
      "21964/21964 [==============================] - 1s 62us/step - loss: 0.8703 - acc: 0.4738 - val_loss: 0.8713 - val_acc: 0.4629\n",
      "Epoch 149/150\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 0.8629 - acc: 0.4771 - val_loss: 0.8627 - val_acc: 0.4586\n",
      "Epoch 150/150\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.8527 - acc: 0.4706 - val_loss: 0.8512 - val_acc: 0.4722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2af86d3e780>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#Con la data pre-procesada capa inicial con activacion lineal con loss categorical_hinge no supero 0,49 \n",
    "model7 = Sequential()\n",
    "model7.add(Dense(30, input_dim=Sx_tr.shape[1], init='uniform', activation='relu'))\n",
    "model7.add(Dense(30, init='uniform', activation='elu'))\n",
    "model7.add(Dense(25, init='uniform', activation='softmax'))\n",
    "model7.compile(optimizer=SGD(lr=0.05), loss='categorical_hinge', metrics=['accuracy'])\n",
    "model7.fit(Sx_tr, to_categorical(y_tr), nb_epoch=150, batch_size=128, verbose=1,\n",
    "                    validation_data=(Sx_v,to_categorical(y_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=784, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(28, activation=\"elu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Alfredo\\Anaconda3\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21964 samples, validate on 5491 samples\n",
      "Epoch 1/50\n",
      "21964/21964 [==============================] - 2s 69us/step - loss: 2.0612 - acc: 0.3532 - val_loss: 1.3961 - val_acc: 0.5223\n",
      "Epoch 2/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 1.0195 - acc: 0.6592 - val_loss: 0.7688 - val_acc: 0.7560\n",
      "Epoch 3/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.5633 - acc: 0.8280 - val_loss: 0.4481 - val_acc: 0.8656\n",
      "Epoch 4/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.2966 - acc: 0.9249 - val_loss: 0.2124 - val_acc: 0.9577\n",
      "Epoch 5/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.1349 - acc: 0.9757 - val_loss: 0.0883 - val_acc: 0.9865\n",
      "Epoch 6/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0538 - acc: 0.9943 - val_loss: 0.0479 - val_acc: 0.9920\n",
      "Epoch 7/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 0.0206 - acc: 0.9990 - val_loss: 0.0124 - val_acc: 0.9998\n",
      "Epoch 8/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0081 - acc: 0.9997 - val_loss: 0.0048 - val_acc: 0.9996\n",
      "Epoch 9/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0243 - val_acc: 0.9924\n",
      "Epoch 11/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0028 - acc: 0.9994 - val_loss: 0.0457 - val_acc: 0.9852\n",
      "Epoch 12/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 5.2105e-04 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 3.2903e-04 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 4.0524e-04 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 7.3617e-04 - acc: 0.9998 - val_loss: 3.1248e-04 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 4.9917e-04 - acc: 0.9999 - val_loss: 2.0077e-04 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 9.0331e-04 - acc: 0.9998 - val_loss: 1.0942e-04 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 1.8160e-04 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 4.4838e-04 - acc: 0.9999 - val_loss: 0.0011 - val_acc: 0.9996\n",
      "Epoch 20/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 2.0861e-04 - acc: 1.0000 - val_loss: 1.9359e-04 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "21964/21964 [==============================] - 1s 60us/step - loss: 4.5088e-04 - acc: 1.0000 - val_loss: 1.3887e-04 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 1.9074e-04 - acc: 0.9999 - val_loss: 4.2518e-05 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 4.5328e-04 - acc: 0.9998 - val_loss: 1.1790e-04 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0068 - val_acc: 0.9987\n",
      "Epoch 25/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 4.1751e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 0.9996\n",
      "Epoch 26/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 7.5307e-04 - acc: 0.9997 - val_loss: 5.4663e-05 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 7.0114e-04 - acc: 0.9997 - val_loss: 3.7762e-04 - val_acc: 0.9998\n",
      "Epoch 28/50\n",
      "21964/21964 [==============================] - 1s 59us/step - loss: 1.1100e-04 - acc: 1.0000 - val_loss: 6.0315e-05 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 7.7641e-04 - acc: 0.9998 - val_loss: 9.8892e-06 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 2.0905e-04 - acc: 0.9999 - val_loss: 4.2022e-05 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 7.8493e-05 - acc: 1.0000 - val_loss: 1.0131e-04 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "21964/21964 [==============================] - 1s 57us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0082 - val_acc: 0.9975\n",
      "Epoch 33/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.2884e-04 - acc: 0.9999 - val_loss: 6.9389e-04 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.5488e-04 - acc: 0.9999 - val_loss: 0.0066 - val_acc: 0.9985\n",
      "Epoch 35/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 3.9275e-05 - acc: 1.0000 - val_loss: 1.3818e-05 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 2.7538e-05 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "21964/21964 [==============================] - 1s 61us/step - loss: 9.0850e-05 - acc: 1.0000 - val_loss: 5.1509e-04 - val_acc: 0.9998\n",
      "Epoch 38/50\n",
      "21964/21964 [==============================] - 1s 60us/step - loss: 3.3773e-04 - acc: 0.9998 - val_loss: 1.9459e-05 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "21964/21964 [==============================] - 1s 62us/step - loss: 8.7219e-06 - acc: 1.0000 - val_loss: 7.9290e-06 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 5.1739e-04 - acc: 0.9999 - val_loss: 8.4199e-04 - val_acc: 0.9998\n",
      "Epoch 41/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 1.9016e-04 - acc: 1.0000 - val_loss: 2.2291e-05 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 1.1079e-04 - acc: 1.0000 - val_loss: 8.0116e-04 - val_acc: 0.9996\n",
      "Epoch 43/50\n",
      "21964/21964 [==============================] - 1s 58us/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0018 - val_acc: 0.9993\n",
      "Epoch 44/50\n",
      "21964/21964 [==============================] - 1s 55us/step - loss: 8.2729e-05 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9995\n",
      "Epoch 45/50\n",
      "21964/21964 [==============================] - 1s 60us/step - loss: 2.6673e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9996\n",
      "Epoch 46/50\n",
      "21964/21964 [==============================] - 1s 56us/step - loss: 7.5028e-04 - acc: 0.9998 - val_loss: 4.8099e-05 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "21964/21964 [==============================] - 1s 54us/step - loss: 5.7392e-04 - acc: 0.9998 - val_loss: 3.6251e-05 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 3.7471e-05 - acc: 1.0000 - val_loss: 8.4789e-05 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "21964/21964 [==============================] - 1s 52us/step - loss: 2.4269e-04 - acc: 0.9998 - val_loss: 2.2527e-05 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "21964/21964 [==============================] - 1s 53us/step - loss: 0.0015 - acc: 0.9997 - val_loss: 2.2281e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27e0292be48>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.np_utils import to_categorical\n",
    "#Con la data pre-procesada una capa\n",
    "#rprop is equivalent to using the gradient but also dividing by the size of the gradient.\n",
    "\"\"\"\n",
    "– The problem with mini-batch rprop is that we divide by a different number \n",
    "for each mini-batch. So why not force the number we divide by to be very \n",
    "similar for adjacent mini-batches?\n",
    "rmsprop: Keep a moving average of the squared gradient for each weight\"\"\"\n",
    "model8 = Sequential()\n",
    "model8.add(Dense(30, input_dim=Sx_tr.shape[1], init='uniform', activation='relu'))\n",
    "model8.add(Dense(28, init='uniform', activation='elu'))\n",
    "model8.add(Dense(25, init='uniform', activation='softmax'))\n",
    "model8.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model8.fit(Sx_tr, to_categorical(y_tr), nb_epoch=50, batch_size=128, verbose=1,\n",
    "                validation_data=(Sx_v,to_categorical(y_v)))\n",
    "\n",
    "###NOS QUEDAMOS CON ESTA, logró val_acc 1 de manera consistente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7172/7172 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.7175697840231314, 0.75669269380925819]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicciones = model8.predict(Sx_t)\n",
    "model8.evaluate(Sx_t, to_categorical(y_t), batch_size=128, verbose=1, sample_weight=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrenaron 8 modelos diferentes de capas, cambiando no solo la cantidad de neuronas en algunos casos, sino también la catidad de capas, se probó con multiples funciones de activación distintas, con distintos optimizadores y funciones de perdida.\n",
    "\n",
    "El ultimo modelo, que fue el con mejor comportamiento en validación, utilizo un optimizador RMSprop, 3 capas con funciones de activación: relu, elu y softmax, en ese orden; con una función de loss cross-entropy y 50 epoch, además de utilizar la data pre-procesada. Como se puede ver logro un error del ~0,25 en test que es un poco más del 0,2 que se pedía.\n",
    "\n",
    "Se pueden destacar los siguientes resultados extra entre las pruebas:\n",
    "\n",
    "1-Si se utiliza loss categorical-hinge la red no puede aprender de buena manera, y jamás pasa del ~60% de accuracy.\n",
    "\n",
    "2-RMSprop converge mucho más rápido a una accuracy muy buena, trabaja en teoría de manera similar a SGD, pero utiliza el tamaño de cada batch sobre el gradiente encontrado, para converger en menor tiempo a una solución local más óptima. De todas maneras se debe tener cuidado de no encerrarse demaciado en una solución ótima local que no es cercana a la mejor global.\n",
    "\n",
    "3-En contra de lo que uno pensaría una función lineal dentro de las primeras capas ayuda mucho a distingir las clases.\n",
    "\n",
    "4-Si se usa una función Sigmoidea en las capas intermedias la red no puede entrenarse, porque no puede realizar backward propagation de buena manera después de esa capa.\n",
    "\n",
    "5-Si se pone una función lineal en la última capa no puede categorizar, lo que hace mucho sentido (no es regresión es categorización).\n",
    "\n",
    "6-Para este ejercicio no es notorio si se divide por 255 los pixeles, que si se dividen por 100.\n",
    "\n",
    "7-Los datos sin procesar no sirven para entrenar las redes, no pueden aprender de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(d) Para la mejor red entrenada anteriormente construya la matriz de confusión de las distintas clases, para\n",
    "asi visualizar cuáles son las clases más difíciles de clasificar y con cuáles se confunden. Comente.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAykAAAKvCAYAAABu9IAbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27e03ccda20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model8.predict(Sx_t)\n",
    "pred =[]\n",
    "for fila in y_pred:\n",
    "    pred.append(np.argmax(fila))\n",
    "A = confusion_matrix(y_t, pred)\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = A\n",
    "df_cm = pd.DataFrame(array, index = [i for i in range(len(A[0]))],\n",
    "                  columns = [i for i in  range(len(A[0]))])\n",
    "plt.figure(figsize = (15,12))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})# font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general la clase 16 es difícil de dicernir de las demás, con la que más tiene confusión es con la clase 9\n",
    "\n",
    "La clase 23 también suele confundirse bastante, de resto el hitmap muestra buenos resultados en al diagonal, con errores pequeños dispersados en la matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(e) Entrene una SVM no lineal sobre los pixeles con y sin pre-procesamiento. Puede utilizar el conjunto de\n",
    "validación para seleccionar hiper-parámetros, como el nivel de regularización aplicado y/o la función\n",
    "de kernel a utilizar.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "Cs = [0.0001,0.01,0.1,1,10,100,1000]\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for k in kernel:\n",
    "    print (\\\"-\\\"*80)\n",
    "    for c in Cs:\n",
    "        clf = SVC(C=c,kernel=k)\n",
    "        clf.fit(x_tr,y_tr)\n",
    "        predTest1 = clf.predict(x_v)\n",
    "        acc1 = accuracy_score(predTest1,y_v)\n",
    "        print (\\\"Score Validación sin Pre-Procesamiento %f\\\"%acc1, \\\", C: \\\", c , \\\"Kernel: \\\", k)\n",
    "    \n",
    "    for k in kernel:\n",
    "        print (\\\"-\\\"*80)\n",
    "        for c in Cs:\n",
    "            clf2 = SVC (C=c,kernel=k)\n",
    "            clf2.fit(Sx_tr,y_tr)\n",
    "            predTest2 = clf2.predict(Sx_v)\n",
    "            acc2 = accuracy_score(predTest2,y_v)\n",
    "            print (\\\"Score Validación Pre-Procesamiento: %f\\\"%acc2, \\\", C: \\\", c , \\\"Kernel: \\\", k)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTADOS:\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  0.0001 Kernel:  linear\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  0.01 Kernel:  linear\\n\"\n",
    "      \n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  0.1 Kernel:  linear\\n\"\n",
    "      \n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  1 Kernel:  linear\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  10 Kernel:  linear\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  100 Kernel:  linear\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  1000 Kernel:  linear\\n\"\n",
    "      \n",
    "-------------------------------------------------------------      \n",
    "      \n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  0.0001 Kernel:  poly\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  0.01 Kernel:  poly\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  0.1 Kernel:  poly\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  1 Kernel:  poly\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  10 Kernel:  poly\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  100 Kernel:  poly\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 1.000000 , C:  1000 Kernel:  poly\\n\"\n",
    "\n",
    "--------------------------------------------------------------\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.047532 , C:  0.0001 Kernel:  rbf\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.047532 , C:  0.01 Kernel:  rbf\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.047532 , C:  0.1 Kernel:  rbf\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.226553 , C:  1 Kernel:  rbf\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.249135 , C:  10 Kernel:  rbf\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.249135 , C:  100 Kernel:  rbf\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.249135 , C:  1000 Kernel:  rbf\\n\"\n",
    "      \n",
    "-------------------------------------------------------------\n",
    "\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.047532 , C:  0.0001 Kernel:  sigmoid\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.047532 , C:  0.01 Kernel:  sigmoid\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.047532 , C:  0.1 Kernel:  sigmoid\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.047532 , C:  1 Kernel:  sigmoid\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.047532 , C:  10 Kernel:  sigmoid\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.047532 , C:  100 Kernel:  sigmoid\\n\"\n",
    "\n",
    "\"Score Validación sin Pre-Procesamiento 0.047532 , C:  1000 Kernel:  sigmoid\\n\"\n",
    "\n",
    "---------------------------------------------------------------\n",
    "      \n",
    "      \n",
    "\"Score Validación Pre-Procesamiento: 0.826443 , C:  0.0001 Kernel:  linear\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 1.000000 , C:  0.01 Kernel:  linear\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 1.000000 , C:  0.1 Kernel:  linear\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 1.000000 , C:  1 Kernel:  linear\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 1.000000 , C:  10 Kernel:  linear\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 1.000000 , C:  100 Kernel:  linear\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 1.000000 , C:  1000 Kernel:  linear\\n\"\n",
    "\n",
    "-------------------------------------------------------------\n",
    "      \n",
    "\"Score Validación Pre-Procesamiento: 0.047714 , C:  0.0001 Kernel:  poly\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.249499 , C:  0.01 Kernel:  poly\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.685485 , C:  0.1 Kernel:  poly\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.976689 , C:  1 Kernel:  poly\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.998725 , C:  10 Kernel:  poly\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.998543 , C:  100 Kernel:  poly\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.998543 , C:  1000 Kernel:  poly\\n\"\n",
    "\n",
    "-------------------------------------------------------------\n",
    "\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.047532 , C:  0.0001 Kernel:  rbf\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.346203 , C:  0.01 Kernel:  rbf\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.909852 , C:  0.1 Kernel:  rbf\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.999818 , C:  1 Kernel:  rbf\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.999818 , C:  10 Kernel:  rbf\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.999818 , C:  100 Kernel:  rbf\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.999818 , C:  1000 Kernel:  rbf\\n\"\n",
    "\n",
    "---------------------------------------------------------------\n",
    "      \n",
    "\"Score Validación Pre-Procesamiento: 0.047532 , C:  0.0001 Kernel:  sigmoid\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.383719 , C:  0.01 Kernel:  sigmoid\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.505008 , C:  0.1 Kernel:  sigmoid\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.421781 , C:  1 Kernel:  sigmoid\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.365143 , C:  10 Kernel:  sigmoid\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.363868 , C:  100 Kernel:  sigmoid\\n\"\n",
    "\n",
    "\"Score Validación Pre-Procesamiento: 0.364779 , C:  1000 Kernel:  sigmoid\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos procesador los kernel lineal, rbf y poly muestran buenos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(f) Entrene una árbol de clasificación sobre los pixeles con y sin pre-procesamiento. Puede utilizar el\n",
    "conjunto de validación para seleccionar hiper-parámetros, como la profundidad máxima del árbol.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "arbol = DTC()\n",
    "arbol.fit(x_tr,y_tr)\n",
    "\n",
    "arbol2 = DTC()\n",
    "arbol2.fit(Sx_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validacion de DTC Sin Pre-Proc: 0.876160990712\n",
      "Score Validacion de DTC Con Pre-Proc: 0.874157712621\n"
     ]
    }
   ],
   "source": [
    "predT1 = arbol.predict(x_v)\n",
    "predT2 = arbol2.predict(Sx_v)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "errorT1 = accuracy_score(predT1,y_v)\n",
    "print(\"Score Validacion de DTC Sin Pre-Proc: \"+str(errorT1))\n",
    "\n",
    "errorT2 = accuracy_score(predT2,y_v)\n",
    "print(\"Score Validacion de DTC Con Pre-Proc: \"+str(errorT2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de DTC Sin Pre-Proc: 0.445203569437\n",
      "Score de DTC Con Pre-Proc: 0.443809258226\n"
     ]
    }
   ],
   "source": [
    "predT1 = arbol.predict(x_t)\n",
    "predT2 = arbol2.predict(Sx_t)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "errorT1 = accuracy_score(predT1,y_t)\n",
    "print(\"Score de DTC Sin Pre-Proc: \"+str(errorT1))\n",
    "\n",
    "errorT2 = accuracy_score(predT2,y_t)\n",
    "print(\"Score de DTC Con Pre-Proc: \"+str(errorT2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados en validación no sugieren que los árboles tengan problemas para generalizar, tanto como si hubo pre-procesamiento como si no, pero estos resultados no se ven reflejados en el conjunto de testeo. Es desconcertante este resultado, porque hasta el momento con el resto de las máquinas no se habia sugerido que el conjunto de validación no fuera representante del conjunto de testeo, pero ahora si surge esa inquietud, de lo contrario es difícil encontrarle una razón a este comportamiento. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
