{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1> INF393 - Máquinas de Aprendizaje  </h1>\n",
    "    <h2> Tarea 3 </h2>\n",
    "    <h3> Universidad Técnica Federico Santa Maria </h3>\n",
    "    \n",
    "</center>\n",
    "\n",
    "_Diciembre 2017_\n",
    "<p>Profesor: R. Ñanculef</p>\n",
    " <p>Ayudante: Francisco Mena</p>\n",
    " <p>Integrantes: \n",
    " <br>Alfredo Silva,\n",
    " 201373511-8</br>\n",
    " <br>Fernando Llorens, 201373528-2</br>\n",
    " \n",
    "\n",
    " \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Small Circle inside Large Circle</h1>\n",
    "<p>\n",
    "El objetivo de esta sección es experimentar con algunos modelos no-lineales sobre un problema de juguete\n",
    "generado para visualizar algoritmos de clustering. Se trata de un problema de clasificación a todas luces\n",
    "linealmente inseparable, en el sentido que, si denotamos por $x∈R^{2}$ un patrón de entrada y por y ∈{−1, 1}\n",
    "su correspondiente etiqueta, no existen $w∈R^{2}$, $b∈R$ tal que y (w$^{T}$ x + b) ≥ ρ > 0. El problema nos permite\n",
    "hacer un recorrido rápido por las grandes ideas en la búsqueda de la no-linealidad.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(a) Escriba una función que genere (aleatoriamente) n datos etiquetados de la forma $\\{(x_1, y_1), . . . ,(x_n, y_n)\\}$,\n",
    "$x_{i}∈R^{2}$, $y_{i}∈\\{0, 1\\}$, con una distribución de probabilidad que refleje la configuración linealmente\n",
    "inseparable que muestra la Fig. 1 (En el PDF original)\n",
    ". Utilice esta función para crear 1000 datos de entrenamiento y 1000 datos de pruebas. Para medir la tendencia de los modelos a sobre-ajuste, agregue un 5 % de ruido al dataset, generando X’s cercanos a la frontera. Genere un gráfico que muestre datos de entrenamiento y pruebas, identificando cada clase con un color diferente.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "def do_circles(n=2000,noisy_n=0.05):\n",
    "    generator = check_random_state(10)\n",
    "    linspace = np.linspace(0, 2 * np.pi, n // 2 + 1)[:-1]\n",
    "    outer_circ_x = np.cos(linspace)\n",
    "    outer_circ_y = np.sin(linspace)\n",
    "    inner_circ_x = outer_circ_x * .3\n",
    "    inner_circ_y = outer_circ_y * .3\n",
    "    X = np.vstack((np.append(outer_circ_x, inner_circ_x),\n",
    "                        np.append(outer_circ_y, inner_circ_y))).T\n",
    "    y = np.hstack([np.zeros(n // 2, dtype=np.intp),\n",
    "                                np.ones(n // 2, dtype=np.intp)])\n",
    "    X += generator.normal(scale=noisy_n, size=X.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "    test_size=0.5, random_state=42)\n",
    "    return X_train,y_train,X_test,y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Para lo que sigue de la actividad utilice la siguiente función para graficar las fronteras de clasificación en\n",
    "base a la probabilidad, definida por un algoritmo, de un ejemplo a pertenecer a una clase en particular.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_classifier(clf,X_train,Y_train,X_test,Y_test,model_type):\n",
    "    f, axis = plt.subplots(1, 1, sharex='col', sharey='row',figsize=(12, 8))\n",
    "    axis.scatter(X_train[:,0],X_train[:,1],s=30,c=Y_train,zorder=10,cmap='cool')\n",
    "    axis.scatter(X_test[:,0],X_test[:,1],s=20,c=Y_test,zorder=10,cmap='Greys')\n",
    "    XX, YY = np.mgrid[-2:2:200j, -2:2:200j]\n",
    "    if model_type == 'tree':\n",
    "        Z = clf.predict_proba(np.c_[XX.ravel(), YY.ravel()])[:,0]\n",
    "    elif model_type == 'ann':\n",
    "        Z = clf.predict(np.c_[XX.ravel(), YY.ravel()])\n",
    "    else: raise ValueError('model type not supported')\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    Zplot = Z >= 0.5\n",
    "    axis.pcolormesh(XX, YY, Zplot ,cmap='YlGn')\n",
    "    axis.contour(XX, YY, Z, alpha=1, colors=[\"k\", \"k\", \"k\"], linestyles=[\"--\", \"-\", \"--\"],\n",
    "    levels=[-2, 0, 2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(b) Demuestre experimentalmente que una red neuronal artificial correspondiente a 1 sola neurona (i.e. sin capas escondidas) no puede resolver satisfactoriamente el problema. Puede utilizar la función de activación y el método de entrenamiento que prefiera. Sea convincente: por ejemplo, intente modificar\n",
    "los parámetros de la máquina de aprendizaje, reportando métricas que permitan evaluar el desempeño\n",
    "del modelo en el problema con cada cambio efectuado. Adapte también la función plot classifier para\n",
    "que represente gráficamente la solución encontrada por la red neuronal. Describa y explique lo que\n",
    "observa, reportando gráficos de la solución sólo para algunos casos representativos.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "n_h=1\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(n_h, init='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer=SGD(lr=1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=100, verbose=1)\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "test_acc = scores[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(c) Demuestre experimentalmente que una red neuronal artificial con 1 capa escondida puede resolver satisfactoriamente\n",
    "el problema obtenido en (a). Puede utilizar la arquitectura y el método de entrenamiento\n",
    "que prefiera, pero en esta actividad puede optar tranquilamente por usar los hiper-parámetros que se\n",
    "entregan como referencia en el código de ejemplo. Cambie el número de neuronas $N_h$ en la red entre 2 y 32 en potencias de 2, graficando el error de entrenamiento y pruebas como función de $N_h$. Describa y explique lo que observa. Utilice la función plot classifier, diseñada anteriormente, para construir gráficos\n",
    "de la solución en algunos casos representativos.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#...\n",
    "n_h=32\n",
    "model = Sequential()\n",
    "model.add(Dense(n_h, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(d) Demuestre experimentalmente que stump (árbol de clasificación de 1 nivel) no puede resolver satisfactoriamente\n",
    "el problema anterior. Puede utilizar el criterio y la función de partición que prefiera. Sea\n",
    "éconvincente: por ejemplo, intente modificar los parámetros de la máquina, reportando metricas que\n",
    "permitan evaluar el desempeño del modelo en el problema con cada cambio efectuado. Adapte también\n",
    "la función plot classifier para que represente gráficamente la solución encontrada por el árbol. Describa\n",
    "y explique lo que observa, reportando gráficos de la solución sólo para algunos casos representativos.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "clf=Tree(criterion='gini',splitter='best',random_state=0,max_depth=1)\n",
    "clf.fit(X_train,Y_train)\n",
    "acc_test = clf.score(X_test,Y_test)\n",
    "print \"Test Accuracy = %f\"%acc_test\n",
    "print clf.tree_.max_depth\n",
    "plot_classifier(clf,X_train,Y_train,X_test,Y_test,'tree')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(e) Demuestre experimentalmente que un árbol de clasificación de múltiples niveles puede resolver satisfactoriamente\n",
    "el problema estudiado. Puede utilizar el criterio y la función de partición que prefiera,\n",
    "pero puede optar tranquilamente por usar los hiper-parámetros que se entregan como referencia en el\n",
    "código de ejemplo. Cambie el número de niveles admitidos en el árbol Nt entre 2 y 20, graficando el\n",
    "error de entrenamiento y pruebas como función de Nt. Describa y explique lo que observa. Utilice la\n",
    "función plot classifier, diseñada anteriormente, para construir gráficos de la solución en algunos casos\n",
    "representativos.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#...\n",
    "n_t=8\n",
    "clf=Tree(criterion='gini',splitter='best',random_state=0,max_depth=n_t)\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(f) Como ya se demostró experimentalmente que este problema es linealmente inseperable, ahora se pide\n",
    "experimentar otra alternativa. Para ello deberá realizar una proyección de los datos a un nuevo espacio\n",
    "dimensional (manifold) en el cual se reconozcan sus patrones no lineales, para poder trabajarlos con\n",
    "fronteras lineales. Utilice la técnica de PCA con la ayuda de un Kernel Gaussiano para extraer\n",
    "sus vectores con dimensión infinita de mayor varianza.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kpca = KernelPCA(n_components=2,kernel=\"rbf\", gamma=5)\n",
    "kpca = kpca.fit(X_train)\n",
    "Xkpca_train = kpca.transform(X_train)\n",
    "Xkpca_test = kpca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(g) Ajuste un algoritmo de aprendizaje con fronteras lineal para los datos proyectados en este nuevo espacio\n",
    "que captura sus componentes no lineales, muestre graficamente que el problema ahora puede ser resulto\n",
    "con estos métodos. Reporte métricas para evaluar el desempeño, comente y concluya.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Bike Sharing: Predicción de Demanda Horaria</h1>\n",
    "<p>\n",
    "En esta sección simularemos nuestra participación en el desafío Bike Sharing Demand de Kaggle. El\n",
    "objetivo es predecir la demanda de bicicletas sobre la red Capital Bikeshare de la ciudad de Washington,\n",
    "D.C., en función de la hora del día y otras variables descritas en la tabla 1. En principio, y como muestra\n",
    "la figura, la función es altamente no lineal y no determinista como función de la hora del día. Su objetivo\n",
    "será entrenar un modelo para obtener un puntaje correspondiente al top-100 del “leaderboard” final, es\n",
    "decir superior o igual a 0.37748.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(a) Cargue los datos de entrenamiento y pruebas como dataframes de pandas. Describa las variables involucradas\n",
    "en el problema, explorando el tipo de datos de que se trata, el número de valores distintos y, si\n",
    "corresponde, un gráfico (e.g. un histograma) que resuma su comportamiento. Su primera operación de\n",
    "pre-procesamiento de datos será obtener la hora del día desde el campo fecha (que en este momento es\n",
    "de tipo string), creando una nueva columna denominada hour y de tipo int. Para hacer esta operación\n",
    "se concatenarán los dataframes de entrenamiento y pruebas y luego se volverán a separar manteniendo\n",
    "la separación original.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dftrain = pd.read_csv('bike_sharing_train.csv')\n",
    "dfval = pd.read_csv('bike_sharing_val.csv')\n",
    "dftest = pd.read_csv('bike_sharing_test.csv')\n",
    "ntrain = len(dftrain)\n",
    "nval = len(dftrain) + len(dfval)\n",
    "df = pd.concat([dftrain,dfval,dftest])\n",
    "print '\\nSummary - dataframe completo:\\n'\n",
    "print df.describe()\n",
    "df['hour'] = pd.to_datetime(df['datetime']).apply(lambda x: x.strftime('%H'))\n",
    "df['hour'] = pd.to_numeric(df['hour'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(b) Entrene un árbol de regresión para resolver el problema usando parámetros por defecto. Con este\n",
    "fin, construya una matriz $X_{train}$ de forma $n_{train} x$ $d1$ que contenga los datos de entrenamiento en sus\n",
    "filas, seleccionando las columnas que desee/pueda utilizar para el entrenamiento. Implemente además, la\n",
    "función de evaluación que hemos definido anteriormente para este problema. Evalúe el árbol de regresión\n",
    "ajustado a los datos de entrenamiento sobre el conjunto de entrenamiento y pruebas. Construya un\n",
    "gráfico que compare las predicciones con los valores reales. En este punto usted debiese tener un modelo\n",
    "con puntaje del orden de 0.59, lo que lo dejará más o menos en la posición 2140 de la competencia.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor as Tree\n",
    "import matplotlib.pyplot as plt\n",
    "def eval_bikemodel(y_predict,y_true):\n",
    "    diff = np.log(y_predict+1.0) - np.log(y_true+1.0)\n",
    "    return np.sqrt(np.sum(np.square(diff))/len(y_predict))\n",
    "Xdf=df.ix[:,['season','holiday','workingday',\n",
    "                'weather','temp','atemp',\n",
    "                'humidity','windspeed','hour']]\n",
    "Ydf=df.ix[:,'count']\n",
    "X_train = Xdf[0:ntrain].values\n",
    "X_val = Xdf[ntrain:nval].values\n",
    "X_test = Xdf[nval:].values\n",
    "Y_train = Ydf[0:ntrain].values\n",
    "Y_val = Ydf[ntrain:nval].values\n",
    "Y_test = Ydf[nval:].values\n",
    "\n",
    "model = Tree(random_state=0)\n",
    "model.fit(X_train,Y_train)\n",
    "score_test = model.score(X_test,Y_test)\n",
    "print \"SCORE TEST=%f\"%score_test\n",
    "\n",
    "Y_pred_train = model.predict(X_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "kagg_train = eval_bikemodel(Y_pred_train,Y_train)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "print \"KAGG EVAL TRAIN =%f\"%kagg_train\n",
    "print \"KAGG EVAL TEST =%f\"%kagg_test\n",
    "plt.plot(Y_test,Y_pred_test,'.')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(c) Mejore el árbol de regresión definido en el punto anterior haciendo modificaciones a los hiper-parámetros\n",
    "del modelo. Por ejemplo, como estos modelos tienden a sobre-ajustar, podría intentar limitar la\n",
    "profundidad del árbol (¿Por qué esto debiese ayudar?). Naturalmente, está absolutamente prohibido\n",
    "tomar este tipo de decisiones en función del resultado de pruebas. Debe realizar estas elecciones evaluando\n",
    "sobre el conjunto de validación. Si no desea utilizarlo, y prefiere implementar validación cruzada\n",
    "u otra técnica automática, tiene la ventaja de poder usar el conjunto de validación como parte del\n",
    "entrenamiento. Con estas modificaciones debiese poder mejorar su ranking en unas 300 posiciones.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Tree(random_state=0,max_depth=20)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(d) Mejore el árbol de regresión definido en el punto anterior haciendo modificaciones sobre la representación\n",
    "utilizada para aprender desde los datos. Por ejemplo, los histogramas que construyó en el punto\n",
    "(a) así como la forma especial de la función de evaluación, sugieren una cierta transformación de la\n",
    "variable respuesta. Podría intentar también normalizando los datos o normalizando la respuesta. Otra\n",
    "opción es intentar rescatar algo más acerca de la fecha (anteriormente sólo se extrajo la hora), como por\n",
    "ejemplo el año o el día de la semana (’lunes’,’martes’, etc) que corresponde. Sea creativo, este paso le\n",
    "debiese reportar un salto de calidad muy significativo. Una observación importante es que si hace una\n",
    "transformación a la variable respuesta (por ejemplo raíz cuadrada), debe invertir esta transformación\n",
    "antes de evaluar el desempeño con eval bikemodel (por ejemplo, elevar al cuadrado si tomó raíz cuadrada).\n",
    "Con modificaciones de este tipo, podría mejorar su ranking en unas 1000 posiciones, entrando\n",
    "ya al top-1000 con un score del orden de 0.45.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['cday'] = pd.to_datetime(df['datetime']).dt.dayofweek#0:lunes,6:domingo\n",
    "df['cday'] = pd.to_numeric(df['cday'])\n",
    "Xdf=df.ix[:,['season','holiday','workingday','weather','temp','atemp',\n",
    "                                'humidity','windspeed','hour','cday']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(e) Entrene una SVM no lineal para resolver el problema midiendo el efecto de las distintas representaciones\n",
    "que haya descubierto hasta este punto. Un detalle importante es que antes de entrenar la SVM sería\n",
    "aconsejable hacer dos tipos de pre-procesamiento adicional de los datos: (i) codificar las variables\n",
    "categóricas en un modo apropiado - por ejemplo como vector binario con un 1 en la posición del\n",
    "valor adoptado-, (ii) escalar los atributos de modo que queden centrados y con rangos comparables.\n",
    "Usando par´ametros por defecto para la SVM debiese obtener un score del orden de 0.344, quedando\n",
    "definitivamente en el top-10 de la competencia.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load dataframes as before ...\n",
    "df = pd.concat([dftrain,dfval,dftest])\n",
    "df['hour'] = pd.to_datetime(df['datetime']).apply(lambda x: x.strftime('%H'))\n",
    "df['cday'] = pd.to_datetime(df['datetime']).dt.dayofweek\n",
    "df['hour'] = pd.to_numeric(df['hour'])\n",
    "df['cday'] = pd.to_numeric(df['cday'])\n",
    "Xdf=df.ix[:,['season','holiday','workingday','weather','temp','atemp',\n",
    "                                'humidity','windspeed','hour','cday']]\n",
    "#PASO IMPORTANTE MAS ABAJO ...\n",
    "Xdf = pd.get_dummies(Xdf,columns=['season', 'weather','hour','cday'])\n",
    "Ydf=df.ix[:,'count']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalerX = StandardScaler()\n",
    "X_train = scalerX.fit_transform(X_train)\n",
    "X_val = scalerX.fit_transform(X_val)\n",
    "X_test = scalerX.transform(X_test)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_train = model.predict(X_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "Y_pred_test = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(f) Mejore la SVM definida en el punto anterior haciendo modificaciones a los hiper-parámetros de la\n",
    "máquina. Naturalmente, está absolutamente prohibido tomar este\n",
    "tipo de decisiones de diseño mirando el resultado de pruebas. Debe realizar estas elecciones evaluando\n",
    "sobre el conjunto de validación. Si no desea utilizarlo, y prefiere implementar validación cruzada\n",
    "u otra técnica automática, tiene la ventaja de poder usar el conjunto de validación como parte del\n",
    "entrenamiento.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SVR(C=1,epsilon=0.01)\n",
    "kagg_train = eval_bikemodel(Y_pred_train,Y_train)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL TRAIN =%f\"%kagg_train\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(g) Evalúe el efecto de utilizar el dataset de validación para entrenamiento y seleccionar los parámetros\n",
    "estructurales del árbol de clasificación y la SVM usando validación cruzada. El código de ejemplo para\n",
    "esto ha sido proporcionado en las tareas 1 y 2, pero se adjunta de nuevo a continuación\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)\n",
    "mse_cv = 0\n",
    "for train, val in kf.split(Xm):\n",
    "    model = #define your model\n",
    "    model.fit(Xm[train], ym[train])\n",
    "    yhat_val = model.predict(Xm[val])\n",
    "    ytrue_val = ym[val]\n",
    "    score_fold = eval_bikemodel(yhat_val,ytrue_val)\n",
    "    mse_cv += score_fold\n",
    "mse_cv = mse_cv / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(h) Evalúe el efecto de utilizar un ensamblado de 2 máquinas de aprendizaje para predecir la demanda\n",
    "total de bicicletas. Un modelo se especializará en la predicción de la demanda de bicicletas de parte\n",
    "de usuarios registrados y otra en la predicción de la demanda de usuarios casuales. Hay razones claras\n",
    "para pensar que los patrones son distintos.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ydf=df.ix[:,'count'] #demanda total\n",
    "Ydf=df.ix[:,'registered'] #demanda registrada\n",
    "Ydf=df.ix[:,'casual'] #demanda casual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(i) Evalúe el efecto de utilizar un algoritmo genérico para ensamblar máquinas de aprendizaje para predecir\n",
    "la demanda total de bicicletas. Puede experimentar con una sola técnica (e.g. Random Forest), discuta\n",
    "la evolución a medida que aumenta el número de máquinas.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=10,max_depth=max_depth,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Calidad de un vino</h1>\n",
    "<p>\n",
    "Dentro de las muchas variedades de vino existentes, algunas gustan más que otras, esto es debido al gusto\n",
    "de una persona en particular o bien a la gran cantidad de químicos y procesos que se aplican a la producción\n",
    "de vino. Para el área de negocios, el estimar cuál es la calidad de un vino en base a la apreciación del público\n",
    "es una tarea bastante difícil.\n",
    "</p>\n",
    "<p>\n",
    "Para esta actividad se trabajará con dos datasets asociados a las variantes tinto y blanco del vino portugués\n",
    "”Vinho Verde”. Debido a temas privados solo se cuenta con las caracterísstcas fisioquímicas asociadas a un\n",
    "vino en particular, los cuales corresponden a 11 atributos numéricos descritos en el siguiente link.\n",
    "Este problema puede ser abordado como clasificación de 11 clases o de regresión, ya que el atributo a estimar,\n",
    "quality, es un valor entero entre 0 y 10.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "(a) Carge los dos dataset en un único dataframe de pandas, además de agregar una columna indicando si\n",
    "es vino tinto o blanco. Describa el dataset a trabajar.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_red = pd.read_csv(\"winequality-red.csv\",sep=\";\")\n",
    "df_white = pd.read_csv(\"winequality-white.csv\",sep=\";\")\n",
    "df = pd.concat([df_red,df_white], axis=0)\n",
    "#genere atributo 'tipo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(b) Aborde este problema como si fuera de clasificación binaria para predecir si un vino es de buena calidad\n",
    "o no, es decir, utilice las distintas características fisioquímicas presentes en los datos para estimar esta\n",
    "etiqueta. Para esto cree las matrices de entrenamiento y de pruebas, además de la etiqueta para ambos\n",
    "conjuntos, considerando como quality mayor a 5 un vino de buena calidad. El conjunto de pruebas\n",
    "(25 %) será utilizado únicamente para verificar la calidad de los algoritmos a entrenar.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['good_quality'] = [1 if q>5 else 0 for q in df.quality] #then remove 'quality' from df\n",
    "#train and test split over df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(c) Entrene un solo Árbol de Clasificación de múltiples niveles para resolver el problema. Puede variar los \n",
    "hiper-parámetros que prefiera, recuerde que las decisiones no pueden ser basadas mirando el conjunto\n",
    "de pruebas. Debido al desbalanceo que se produce en las dos clases mida la métrica F1-score sobre\n",
    "el conjunto de entrenamiento y de pruebas.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(d) Entrene un ensamblador de árboles de múltiples niveles, mediante la técnica de Random Forest. Varíe la\n",
    "cantidad de árboles de decisión utilizados en el ensamblado (n estimators), realice un gráfico resumen\n",
    "del F1-score de entrenamiento y de pruebas en función de este hiper-parámetro.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=, max_depth=,n_jobs=-1)\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(e) Entrene un ensamblador de árboles de múltiples niveles, mediante la técnica de AdaBoost. Varíe la\n",
    "cantidad de árboles de decisión utilizados en el ensamblado (n estimators), realice un gráfico resumen\n",
    "del F1-score de entrenamiento y de pruebas en función de este hiper-parámetro. Compare y analice con\n",
    "la técnica utilizada en d).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(base_estimator=Tree(max_depth=), n_estimators=)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(f) Entrene alguna otra máquina de aprendizaje, elegida por usted, para resolver este problema. Elija los\n",
    "hiper-par´ametros que estime convenientes intentando aumentar el F1-score obtenido por los algoritmos\n",
    "anteriores. Compare y analice estas 4 maneras de resolver el problema definido en b).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(g) Defina un criterio para estimar la importancia de los distintos atributos en el ensamblado de Random\n",
    "Forest, implementelo sobre alguno de los ensambladores entrenados en d), haga un ranking de\n",
    "importancia de atributos ¿Es posible implementar este criterio sobre una técnica de boost como lo es\n",
    "AdaBoost?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4. Reconocimiento de Imágenes Sign Gestures</h1>\n",
    "<p>\n",
    "MNIST es un dataset muy popular de dígitos escrito a mano que a servido para probar distintos algoritmos\n",
    "de Machine Learning relacionados con Computer Vision. Buscando nuevos desafíos, investigadores generaron\n",
    "un dataset que podría usarse eventualmente en aplicaciones reales, Sign Gestures, consta de imagenes del\n",
    "lenguaje de señas, estas tienen una resolución de 28x28 pixeles representados en una escala de grises 0-255.\n",
    "La versión utilizada se atribuye a y viene separada en 27455 ejemplos de entrenamiento y 7172 casos de\n",
    "pruebas. Las clases son mutualmente excluyentes y corresponden a las letras del alfabeto (imagen en PDF original).\n",
    "</p>\n",
    "<p>\n",
    "(a) Construya una función que cargue todos los datos de entrenamiento y pruebas del problema generando\n",
    "como salida: (i) dos matrices $X_{tr}$, $Y_{tr}$, correspondientes a las imágenes y etiquetas de entrenamiento,\n",
    "(ii) dos matrices $X_t$, $Y_t$, correspondientes a las imágenes y etiquetas de pruebas, y finalmente (iii) dos\n",
    "matrices $X_v$, $Y_v$, correspondientes a imágenes y etiquetas que se usarán como conjunto de validación, es\n",
    "decir para tomar decisiones de diseño acerca del modelo. Este último conjunto debe ser extraído desde\n",
    "el conjunto de entrenamiento original y no debe superar las 7000 imágenes.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "def load_data():\n",
    "    train = pd.read_csv('sign_mnist_train.csv')\n",
    "    test = pd.read_csv('sign_mnist_test.csv')\n",
    "    y_tr = train['label']\n",
    "    x_tr = train.iloc[:,1:]\n",
    "    y_t = test['label']\n",
    "    x_t = test.iloc[:,1:]\n",
    "    #you need to add Xval: x_v,y_v\n",
    "    return(x_tr,x_v,x_t,y_tr,y_v,y_t)\n",
    "x_tr, x_v, x_t, y_tr, y_v , y_t= load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(b) Construya una función que escale apropiadamente las imágenes antes de trabajar. Experimente sólo\n",
    "escalando los datos de acuerdo a la intensidad máxima de pixel (i.e., dividiendo por 255) y luego\n",
    "centrando y escalándolos como en actividades anteriores.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(c) Diseñe, entrene y evalúe una red neuronal para el problema partir de la representación original de las\n",
    "imágenes. Experimente con distintas arquitecturas, pre-procesamientos y métodos de entrenamiento,\n",
    "midiendo el error de clasificación sobre el conjunto de validación. En base a esta última medida de\n",
    "desempeño, decida qué modelo, de entre todos los evaluados, medirá finalmente en el conjunto de test.\n",
    "Reporte y discuta los resultados obtenidos. Se espera que logre obtener un error de pruebas menor o\n",
    "igual a 0.2.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=x_tr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dense(30, init='uniform', activation='relu'))\n",
    "model.add(Dense(25, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_tr.values, to_categorical(y_tr), nb_epoch=100, batch_size=128, verbose=1,\n",
    "validation_data=(x_v.values,to_categorical(y_v)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>(d) Para la mejor red entrenada anteriormente construya la matriz de confusión de las distintas clases, para\n",
    "asi visualizar cuáles son las clases más difíciles de clasificar y con cuáles se confunden. Comente.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(e) Entrene una SVM no lineal sobre los pixeles con y sin pre-procesamiento. Puede utilizar el conjunto de\n",
    "validación para seleccionar hiper-par´ametros, como el nivel de regularización aplicado y/o la función\n",
    "de kernel a utilizar.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "(f) Entrene una árbol de clasificación sobre los pixeles con y sin pre-procesamiento. Puede utilizar el\n",
    "conjunto de validación para seleccionar hiper-parámetros, como la profundidad máxima del árbol.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
